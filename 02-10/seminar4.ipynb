{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DY6KfR5twAZ2"
   },
   "source": [
    "## Семинар 4\n",
    "\n",
    "# Тема: Линейная регрессия с m признаками"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная регрессия – это модель линейной зависимости между признаками и целевой переменной.\n",
    "\n",
    "$X \\in{\\mathbb R}^{\\displaystyle n \\times m}$, $\\vec y \\in {\\mathbb R}^{1}$\n",
    "\n",
    "$X=\\begin{pmatrix}\n",
    "  x_{1 1} & x_{1 2}& \\dots & x_{1 m}\\\\\n",
    "   \\vdots &  \\vdots & \\dots &  \\vdots\\\\\n",
    "   x_{n 1} & x_{n 2}& \\dots & x_{n m}\n",
    "\\end{pmatrix}$ - матрица признаков, $\\quad \\vec{y}=\\begin{pmatrix}\n",
    "  y_1\\\\\n",
    "   \\vdots \\\\\n",
    "  y_n\n",
    "\\end{pmatrix}$ - вектор-столбец целевой переменной\n",
    "\n",
    "Модель: $\\hat{y} = w_0 + w_1 x_1+ w_2 x_2 + \\dots + w_m x_m$ - предсказанные значения (гиперплоскость)\n",
    "\n",
    "\n",
    "$\\left\\{\n",
    "\\begin{array}{ccc}\n",
    "\\hat{y}_1 = w_0 + w_1 x_{1 1}+ w_2 x_{1 2}+\\dots + w_m x_{1 m}\\\\\n",
    "\\hat{y}_2 = w_0 + w_1 x_{2 1}+ w_2 x_{2 2}+\\dots + w_m x_{2 m}\\\\\n",
    " \\ldots \\\\\n",
    "\\hat{y}_n = w_0 + w_1 x_{n 1}+ w_2 x_{n 2}+\\dots + w_m x_{n m}\\\\\n",
    "\\end{array}\n",
    "\\right.\n",
    "\\qquad \\Rightarrow \\qquad   \\hat{y}_i = w_0 + w_1 x_{i 1}+ w_2 x_{i 2}+\\dots + w_m x_{i m}, \\quad i= 1,\\dots , n $\n",
    "\n",
    "Ошибка MSE (mean squared error):\n",
    "$L =  \\frac{1}{n}\\sum_{i=1}^{n} (\\hat{y}_i - {y}_i)^2$\n",
    "\n",
    "Функция ошибки:\n",
    "$L(w_0, w_1, w_2,\\dots , w_m) =  \\frac{1}{n}\\sum_{i=1}^{n} ( w_0 + w_1 x_{i 1}+ w_2 x_{i 2}+\\dots + w_m x_{i m} - {y}_i)^2 \\quad \\longrightarrow_{w_0, w_1, w_2,\\dots , w_m} \\quad min$\n",
    "\n",
    "Найдём частные производные:\n",
    "\n",
    "$ \\frac{\\partial }{\\partial w_0}L(w_0,w_1, w_2,\\dots, w_m) =\\frac{2}{n}\\sum_{i=1}^{n} ( w_0 + w_1 x_{i 1}+ w_2 x_{i 2}+\\dots + w_m x_{i m} - {y}_i)$\n",
    "\n",
    "$\\frac{\\partial }{\\partial w_1}L(w_0,w_1, w_2,\\dots , w_m) =\\frac{2}{n}\\sum_{i=1}^{n} ( w_0 + w_1 x_{i 1}+ w_2 x_{i 2}+\\dots + w_m x_{i m} - {y}_i){x}_{i 1}$\n",
    "\n",
    "$\\frac{\\partial }{\\partial w_2}L(w_0,w_1, w_2,\\dots , w_m) =\\frac{2}{n}\\sum_{i=1}^{n} ( w_0 + w_1 x_{i 1}+ w_2 x_{i 2}+\\dots + w_m x_{i m} - {y}_i){x}_{i 2}$\n",
    "\n",
    "$\\dots$\n",
    "\n",
    "$\\frac{\\partial }{\\partial w_m}L(w_0,w_1, w_2,\\dots , w_m) =\\frac{2}{n}\\sum_{i=1}^{n} ( w_0 + w_1 x_{i 1}+ w_2 x_{i 2}+\\dots + w_m x_{i m} - {y}_i){x}_{i m}$\n",
    "\n",
    "**Метод градиентного спуска в случае линейной регрессии**\n",
    "\n",
    "$\\left\\{\n",
    "\\begin{array}{ccc}\n",
    "w_{0}^{j+1} = w_{0}^{j} - \\alpha \\frac{1}{n}\\sum_{i=1}^{n} (w_0^{j} + w_1^{j} {x}_{i 1} + w_2^{j} x_{i 2}+\\dots + w_m x_{i m} - {y}_i)\\\\\n",
    "w_{1}^{j+1} = w_{1}^{j} - \\alpha \\frac{1}{n}\\sum_{i=1}^{n} (w_0^{j} + w_1^{j} {x}_{i 1} + w_2^{j} x_{i 2}+\\dots + w_m x_{i m} - {y}_i){x}_{i 1}\\\\\n",
    "\\dots \\\\\n",
    "w_{m}^{j+1} = w_{m}^{j} - \\alpha \\frac{1}{n}\\sum_{i=1}^{n} (w_0^{j} + w_1^{j} {x}_{i 1} + w_2^{j} x_{i 2}+\\dots + w_m x_{i m} - {y}_i){x}_{i m}\\\n",
    "\\end{array}\n",
    "\\right.\n",
    ", \\quad j= 1,\\dots , k-1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JE3-i5DkwAZ9"
   },
   "source": [
    "### Матричный вид:\n",
    "\n",
    "Формулы очень громоздкие, запишем их в матричном виде:\n",
    "\n",
    "$\\tilde{X}=\\begin{pmatrix}\n",
    "1 &  x_{1 1} & x_{1 2}& \\dots & x_{1 m}\\\\\n",
    "   \\vdots &  \\vdots & \\dots &  \\vdots\\\\\n",
    "1 &  x_{n 1} & x_{n 2}& \\dots & x_{n m}\n",
    "\\end{pmatrix}$ - матрица признаков с добавленным столбцом из едениц,\n",
    "\n",
    "$\\quad \\vec{y}=\\begin{pmatrix}\n",
    "  y_1\\\\\n",
    "   \\vdots \\\\\n",
    "  y_n\n",
    "\\end{pmatrix}$ - вектор-столбец целевой переменной,\n",
    "\n",
    "$\\quad \\vec{w}=\\begin{pmatrix}\n",
    "w_0\\\\\n",
    "w_1\\\\\n",
    "\\vdots \\\\\n",
    "w_m\n",
    "\\end{pmatrix}$ - вектор-столбец параметров гиперплоскости,\n",
    "\n",
    "$\\vec{\\hat{y}} = \\tilde{X}\\vec{w}$ - вектор-столбец предсказанных значений\n",
    "\n",
    "Функция ошибки MSE: $L = \\frac{1}{n}(\\tilde{X}\\vec{w}- \\vec{y})^{T}(\\tilde{X}\\vec{w}- \\vec{y})$\n",
    "\n",
    "Найдём частные производные:\n",
    "\n",
    "$\\begin{pmatrix}\n",
    "  \\frac{\\partial L}{\\partial w_0}\\\\\n",
    "  \\frac{\\partial L}{\\partial w_1}\\\\\n",
    "   \\vdots \\\\\n",
    " \\frac{\\partial L}{\\partial w_m}\n",
    "\\end{pmatrix}=\\frac{2}{n}\\tilde{X}^T(\\tilde{X}\\vec{w}- \\vec{y})$\n",
    "\n",
    "**Метод градиентного спуска в случае линейной регрессии:**\n",
    "\n",
    "$\\vec{w}^{j+1} = \\vec{w}^{j} - \\alpha \\frac{1}{n}\\tilde{X}^T(\\tilde{X}\\vec{w}^{j+1}- \\vec{y}), \\quad j= 1,\\dots , k$\n",
    "\n",
    "Градиентный спуск может быть усовершенствован до стохастического градиентного спуска, при котором вычисления производятся не на всех данных, а на наборах объектов, выбранных случайным образом из всех данных, что уменьшает требования по памяти."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACeps3L6vUXM"
   },
   "source": [
    "## Аналитическое решение\n",
    "\n",
    "Найти вектор оптимальных весов $w$ можно аналитически.\n",
    "Нужно найти такой вектор весов $w$, чтобы  выполнялось матричное уравнение:\n",
    "\n",
    "$\\vec{{y}} = \\tilde{X}\\vec{w}$.\n",
    "\n",
    "Домножим слева обе части на $\\tilde{X}^T$:\n",
    "\n",
    "$\\tilde{X}^T\\vec{{y}} = \\tilde{X}^T\\tilde{X}\\vec{w}$.\n",
    "\n",
    "Матрица $\\tilde{X}^T\\tilde{X}$ - квадратная, тогда можно найти решение (вектор $\\vec{w}$) в виде:\n",
    "\n",
    "$\\vec{w} = {(\\tilde{X}^T\\tilde{X})}^{-1}\\tilde{X}^T\\vec{{y}}$.\n",
    "\n",
    "У этого метода есть недостаток.\n",
    "Нахождение матрицы ${(\\tilde{X}^T\\tilde{X})}^{-1}$ - операция вычислительно сложная в случае большого размера матрицы и нестабильная в случае малого определителя матрицы $\\tilde{X}^T\\tilde{X}$.\n",
    "\n",
    "На практике лучше находить вектор весов $\\vec w$ решением матричного уравнения\n",
    "$\\tilde{X}^T\\tilde{X}\\vec{w}= \\tilde{X}^T\\vec{{y}}$. Оно называется нормальным. Это может быть сделано с помощью функции [numpy.linalg.solve](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.linalg.solve.html).\n",
    "\n",
    "Для небольшого датасета быстрее будет получаться аналитическое решение, но для больших матриц $\\tilde{X}$ быстрее работает градиентный спуск, особенно его стохастическая версия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VtKkv70TwAZ_"
   },
   "source": [
    "Импортируем необходимые библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Yg-3Xb1uwAZ_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "import time\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели линейной регрессии на sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генерируем данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_regression(n_samples=1000, # число строк\n",
    "                          n_features=5,    # число признаков\n",
    "                          n_informative=5, # целевая переменная зависит от всех признаков\n",
    "                          noise = 5,\n",
    "                          bias = 2,\n",
    "                          random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём модель (объект класса) линейной регрессии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Y56H_RcgwAaX"
   },
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "iRMGN_qYwAaX",
    "outputId": "037e5c56-12d5-4456-d0cd-259c7645135b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводим найденные коэффициенты линейной регрессии.\n",
    "\n",
    "Свободный коэффициент:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MIkqUYtPwAaY",
    "outputId": "f15d9117-4885-4df1-a981-f170ddc1194b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.691426699296051)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Веса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f_lOeOwrwAaY",
    "outputId": "c823742a-4203-4444-b48e-911aa4d3d073"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28.34273825, 46.0063814 , 16.71776866, 24.63911531, 19.1812038 ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDblKsG4wAaA"
   },
   "source": [
    "### 1. Сгенерируйте данные и значения целевой переменной (метки) для задачи регрессии, имеющие 5 признаков и 10000 наблюдений. Причём целевая переменная должна зависеть только от 3 признаков. Запишите их в датафрейм, дав названия колонкам. Выведите первые 10 строк датафрейма, а также его описательную статистику.\n",
    "Указание: Для этого воспользуйтесь [make_regression](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html), задав параметры: число строк n_samples=10000, число признаков n_features=5, число признаков от которых зависит целевая переменная n_informative=3, фиксируем воспроизводимость случайных данных        random_state=0. Дайте названия колонкам датафрейма, например, признакам - x1, x2, ..., а целевой переменной - y. Описательная статистика выводится при помощи метода pandas [describe](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_regression(n_samples=10000, # число строк\n",
    "                          n_features=5,    # число признаков\n",
    "                          n_informative=3, # целевая переменная зависит от всех признаков\n",
    "                          random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.76185354,  0.8715765 ,  1.09439478,  0.183368  ,  0.02913489],\n",
       "       [-0.4309962 , -1.25135618, -0.54719179, -1.10687029,  1.33450613],\n",
       "       [-0.4478858 ,  1.97822297, -1.3211183 ,  0.85332424, -1.47937352],\n",
       "       [ 0.02050173,  0.75204638,  1.33321056,  0.65336838, -1.07119486],\n",
       "       [ 1.29914982,  0.33323053, -0.24733596,  0.33271933, -1.33314801]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.761854</td>\n",
       "      <td>0.871577</td>\n",
       "      <td>1.094395</td>\n",
       "      <td>0.183368</td>\n",
       "      <td>0.029135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.430996</td>\n",
       "      <td>-1.251356</td>\n",
       "      <td>-0.547192</td>\n",
       "      <td>-1.106870</td>\n",
       "      <td>1.334506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.447886</td>\n",
       "      <td>1.978223</td>\n",
       "      <td>-1.321118</td>\n",
       "      <td>0.853324</td>\n",
       "      <td>-1.479374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.020502</td>\n",
       "      <td>0.752046</td>\n",
       "      <td>1.333211</td>\n",
       "      <td>0.653368</td>\n",
       "      <td>-1.071195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.299150</td>\n",
       "      <td>0.333231</td>\n",
       "      <td>-0.247336</td>\n",
       "      <td>0.332719</td>\n",
       "      <td>-1.333148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>-0.108076</td>\n",
       "      <td>0.681314</td>\n",
       "      <td>0.390398</td>\n",
       "      <td>0.924574</td>\n",
       "      <td>-0.853174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>-0.323143</td>\n",
       "      <td>-0.237544</td>\n",
       "      <td>-1.079891</td>\n",
       "      <td>0.334889</td>\n",
       "      <td>-0.378978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.591341</td>\n",
       "      <td>0.830118</td>\n",
       "      <td>0.889318</td>\n",
       "      <td>0.345944</td>\n",
       "      <td>-0.130071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>-0.458137</td>\n",
       "      <td>-1.026625</td>\n",
       "      <td>-0.533452</td>\n",
       "      <td>-0.377531</td>\n",
       "      <td>1.257613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>-0.654220</td>\n",
       "      <td>-1.176382</td>\n",
       "      <td>1.775847</td>\n",
       "      <td>1.297774</td>\n",
       "      <td>-1.108053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x1        x2        x3        x4        x5\n",
       "0    -0.761854  0.871577  1.094395  0.183368  0.029135\n",
       "1    -0.430996 -1.251356 -0.547192 -1.106870  1.334506\n",
       "2    -0.447886  1.978223 -1.321118  0.853324 -1.479374\n",
       "3     0.020502  0.752046  1.333211  0.653368 -1.071195\n",
       "4     1.299150  0.333231 -0.247336  0.332719 -1.333148\n",
       "...        ...       ...       ...       ...       ...\n",
       "9995 -0.108076  0.681314  0.390398  0.924574 -0.853174\n",
       "9996 -0.323143 -0.237544 -1.079891  0.334889 -0.378978\n",
       "9997  0.591341  0.830118  0.889318  0.345944 -0.130071\n",
       "9998 -0.458137 -1.026625 -0.533452 -0.377531  1.257613\n",
       "9999 -0.654220 -1.176382  1.775847  1.297774 -1.108053\n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(X, columns=[f'x{i+1}' for i in range(X.shape[1])])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.001002</td>\n",
       "      <td>-0.004993</td>\n",
       "      <td>-0.010528</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.014416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.989240</td>\n",
       "      <td>0.994265</td>\n",
       "      <td>1.005219</td>\n",
       "      <td>1.014868</td>\n",
       "      <td>0.997083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.856375</td>\n",
       "      <td>-3.631539</td>\n",
       "      <td>-3.635200</td>\n",
       "      <td>-4.295391</td>\n",
       "      <td>-4.465604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.664076</td>\n",
       "      <td>-0.675572</td>\n",
       "      <td>-0.704792</td>\n",
       "      <td>-0.696539</td>\n",
       "      <td>-0.654058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.000210</td>\n",
       "      <td>0.006501</td>\n",
       "      <td>-0.019121</td>\n",
       "      <td>0.012872</td>\n",
       "      <td>0.006485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.679485</td>\n",
       "      <td>0.662879</td>\n",
       "      <td>0.676844</td>\n",
       "      <td>0.683884</td>\n",
       "      <td>0.683468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.852731</td>\n",
       "      <td>4.479084</td>\n",
       "      <td>3.691625</td>\n",
       "      <td>3.926238</td>\n",
       "      <td>3.942331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 x1            x2            x3            x4            x5\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000\n",
       "mean      -0.001002     -0.004993     -0.010528      0.000002      0.014416\n",
       "std        0.989240      0.994265      1.005219      1.014868      0.997083\n",
       "min       -3.856375     -3.631539     -3.635200     -4.295391     -4.465604\n",
       "25%       -0.664076     -0.675572     -0.704792     -0.696539     -0.654058\n",
       "50%       -0.000210      0.006501     -0.019121      0.012872      0.006485\n",
       "75%        0.679485      0.662879      0.676844      0.683884      0.683468\n",
       "max        3.852731      4.479084      3.691625      3.926238      3.942331"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Убелитесь в том, что в сгенерированных данных целевая переменная действительно зависит от трёх переменных. \n",
    "Указание: Для этого вычислите матрицу корреляции, воспользовавшись методом [corr](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html) библиотеки pandas. Для наглядности изобразите её на тепловой карте [heatmap](https://seaborn.pydata.org/generated/seaborn.heatmap.html) библиотеки seaborn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.002876</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.004908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2</th>\n",
       "      <td>-0.002876</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003873</td>\n",
       "      <td>0.012809</td>\n",
       "      <td>-0.002124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x3</th>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.003873</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.007831</td>\n",
       "      <td>-0.011626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x4</th>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.012809</td>\n",
       "      <td>0.007831</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x5</th>\n",
       "      <td>0.004908</td>\n",
       "      <td>-0.002124</td>\n",
       "      <td>-0.011626</td>\n",
       "      <td>0.009227</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x1        x2        x3        x4        x5\n",
       "x1  1.000000 -0.002876  0.000074  0.000603  0.004908\n",
       "x2 -0.002876  1.000000  0.003873  0.012809 -0.002124\n",
       "x3  0.000074  0.003873  1.000000  0.007831 -0.011626\n",
       "x4  0.000603  0.012809  0.007831  1.000000  0.009227\n",
       "x5  0.004908 -0.002124 -0.011626  0.009227  1.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(df.corr(), annot=True, fmt='.2f')\n",
    "plt.title('Матрица корреляции')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Напишите функцию X_, которая принимает матрицу X (двумерный numpy-массив) и присоединяет столбец единиц к X слева. Примените функцию к сгенерированным выше данным X.\n",
    "Указание: Можно воспользоваться методом concatenate, либо hstack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def X_(X):\n",
    "    X_ones = np.ones((X.shape[0], 1))\n",
    "    return np.hstack([X_ones, X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.76185354,  0.8715765 ,  1.09439478,  0.183368  ,\n",
       "         0.02913489],\n",
       "       [ 1.        , -0.4309962 , -1.25135618, -0.54719179, -1.10687029,\n",
       "         1.33450613],\n",
       "       [ 1.        , -0.4478858 ,  1.97822297, -1.3211183 ,  0.85332424,\n",
       "        -1.47937352],\n",
       "       ...,\n",
       "       [ 1.        ,  0.59134132,  0.83011766,  0.88931791,  0.34594367,\n",
       "        -0.13007084],\n",
       "       [ 1.        , -0.45813699, -1.02662548, -0.53345245, -0.37753115,\n",
       "         1.25761311],\n",
       "       [ 1.        , -0.65422026, -1.17638185,  1.77584689,  1.29777381,\n",
       "        -1.10805333]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.761854</td>\n",
       "      <td>0.871577</td>\n",
       "      <td>1.094395</td>\n",
       "      <td>0.183368</td>\n",
       "      <td>0.029135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.430996</td>\n",
       "      <td>-1.251356</td>\n",
       "      <td>-0.547192</td>\n",
       "      <td>-1.106870</td>\n",
       "      <td>1.334506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.447886</td>\n",
       "      <td>1.978223</td>\n",
       "      <td>-1.321118</td>\n",
       "      <td>0.853324</td>\n",
       "      <td>-1.479374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020502</td>\n",
       "      <td>0.752046</td>\n",
       "      <td>1.333211</td>\n",
       "      <td>0.653368</td>\n",
       "      <td>-1.071195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.299150</td>\n",
       "      <td>0.333231</td>\n",
       "      <td>-0.247336</td>\n",
       "      <td>0.332719</td>\n",
       "      <td>-1.333148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.108076</td>\n",
       "      <td>0.681314</td>\n",
       "      <td>0.390398</td>\n",
       "      <td>0.924574</td>\n",
       "      <td>-0.853174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.323143</td>\n",
       "      <td>-0.237544</td>\n",
       "      <td>-1.079891</td>\n",
       "      <td>0.334889</td>\n",
       "      <td>-0.378978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.591341</td>\n",
       "      <td>0.830118</td>\n",
       "      <td>0.889318</td>\n",
       "      <td>0.345944</td>\n",
       "      <td>-0.130071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.458137</td>\n",
       "      <td>-1.026625</td>\n",
       "      <td>-0.533452</td>\n",
       "      <td>-0.377531</td>\n",
       "      <td>1.257613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.654220</td>\n",
       "      <td>-1.176382</td>\n",
       "      <td>1.775847</td>\n",
       "      <td>1.297774</td>\n",
       "      <td>-1.108053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5\n",
       "0     1.0 -0.761854  0.871577  1.094395  0.183368  0.029135\n",
       "1     1.0 -0.430996 -1.251356 -0.547192 -1.106870  1.334506\n",
       "2     1.0 -0.447886  1.978223 -1.321118  0.853324 -1.479374\n",
       "3     1.0  0.020502  0.752046  1.333211  0.653368 -1.071195\n",
       "4     1.0  1.299150  0.333231 -0.247336  0.332719 -1.333148\n",
       "...   ...       ...       ...       ...       ...       ...\n",
       "9995  1.0 -0.108076  0.681314  0.390398  0.924574 -0.853174\n",
       "9996  1.0 -0.323143 -0.237544 -1.079891  0.334889 -0.378978\n",
       "9997  1.0  0.591341  0.830118  0.889318  0.345944 -0.130071\n",
       "9998  1.0 -0.458137 -1.026625 -0.533452 -0.377531  1.257613\n",
       "9999  1.0 -0.654220 -1.176382  1.775847  1.297774 -1.108053\n",
       "\n",
       "[10000 rows x 6 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Напишите функцию, вычисляющую предсказание значения целевой переменной, как линейную функцию признака $\\vec{\\hat{y}} =\\tilde{X}\\vec{w}$, где $\\tilde{X} $ - матрица признаков с присоединённым слева столбцом единиц. Назовите её predict. Вычислите её значения на сгенерированных данных X в случайной точке $w$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, w):\n",
    "    return np.dot(X_(X), w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.91346662, -1.91982641,  1.10475974, ...,  1.9554665 ,\n",
       "       -1.04999707,  1.24191684])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(X, np.random.random(X.shape[1]+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Напишите функцию ошибки (loss) линейной регрессии с множеством признаков в матричном виде. Примените функцию к сгенерированным выше данным X, y, а в качестве $w$ возьмите столбец случайных чисел.\n",
    "Указание: $L = \\frac{1}{n}(\\tilde{X}\\vec{w}- \\vec{y})^{T}(\\tilde{X}\\vec{w}- \\vec{y})$, здесь $\\tilde{X}$ - это матрица X c присоединённым к ней столбцом единиц слева, а n - число строк матрицы X. Число элементов в $w$ должно соответствовать количеству столбцов в $\\tilde{X}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(X, y, w):\n",
    "    return (1/X.shape[0]) * np.dot((predict(X, w) - y).T, predict(X, w) - y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(9748.625937774685)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(X, y, np.random.random(X.shape[1]+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dejU_eixwAaE"
   },
   "source": [
    "### 6. Напишите функцию, которая вычисляет градиент функции ошибки (loss) с множеством признаков в матричном виде. Примените функцию к сгенерированным выше данным X, y, а в качестве $w$ возьмите столбец случайных чисел.\n",
    "\n",
    "Указание: $\\overrightarrow{{grad} (L)}  = \\frac{2}{n}\\tilde{X}^T(\\tilde{X}\\vec w- \\vec y)$, здесь $\\tilde{X}$ - это матрица X c присоединённым к ней столбцом единиц слева, а n - число строк матрицы X. Назовите созданную функцию gradient_F. Примените функцию к сгенерированным выше данным X, y, а в качестве $w$ возьмите столбец случайных чисел."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_f(X, y, w):\n",
    "    return (2/X.shape[0])*X_(X).transpose()@(predict(X, w) - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.70063347e+00, -9.86148551e-02, -3.32914879e-01, -1.82111144e+02,\n",
       "       -9.03757111e-01, -7.25044087e+01])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_f(X, y, np.random.random(X.shape[1]+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cfvz4uwJwAaF"
   },
   "source": [
    "### 7. Создайте класс Linear_Regression_GD, реализующий модель линейной регрессии для данных имеющих произвольное количество признаков (столбцов). Создайте экземпляр класса, обучите модель и выведите получившиеся коэффициенты гиперплоскости (смещение и веса).\n",
    "Указание: Необходимо создать класс, реализующий метод градиентного спуска для функции ошибки L.\n",
    "Воспользуйтесь для этого классом GradientDiscent, написанный в предыдущих ноутбуках, подставив туда методы X_ и gradient_L. В методе fit задайте стартовое значение массивом нулей нужной длины. В функции GD параметры a и b можно заменить на X, y для наглядности."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class GradientDiscent():\n",
    "    def __init__(self, max_iter):\n",
    "        self.w = None\n",
    "        self.max_iter_ = max_iter\n",
    "    \n",
    "    def gradient_F(self, X, y):\n",
    "        \n",
    "        return ........\n",
    "        \n",
    "    def GD(self, a, b, w_start, learning_rate=0.2):\n",
    "        self.w = w_start\n",
    "\n",
    "        for _ in range(self.max_iter_):\n",
    "            self.w = self.w - learning_rate *self.gradient_F(a, b)\n",
    "        assert (-1e+06 < self.w).all() and (self.w < 1e+06).all(), \"Расходимость: слишком большой learning_rate, либо неудачно выбрана начальная точка, либо минимум не достигается\"\n",
    "        assert (-1e-04 < self.gradient_F(a, b)).all() and (self.gradient_F(a, b) < 1e-04).all(), \"Недостаточно шагов градиентного спуска\"\n",
    "        \n",
    "    def fit(self, a, b):\n",
    "        w_start = np.zeros(2)\n",
    "        self.GD(a, b, w_start)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear_Regression_GD():\n",
    "    def __init__(self, max_iter):\n",
    "        self.w = None\n",
    "        self.max_iter_ = max_iter\n",
    "\n",
    "    def X_(self, X):\n",
    "        X_ones = np.ones((X.shape[0], 1))\n",
    "        return np.hstack([X_ones, X])\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.dot(X_(X), self.w)\n",
    "    \n",
    "    def gradient_F(self, X, y):\n",
    "        return (2/X.shape[0])*X_(X).transpose()@(self.predict(X) - y)\n",
    "        \n",
    "    def GD(self, a, b, w_start, learning_rate=0.2):\n",
    "        self.w = w_start\n",
    "\n",
    "        for _ in range(self.max_iter_):\n",
    "            self.w = self.w - learning_rate *self.gradient_F(a, b)\n",
    "        assert (-1e+06 < self.w).all() and (self.w < 1e+06).all(), \"Расходимость: слишком большой learning_rate, либо неудачно выбрана начальная точка, либо минимум не достигается\"\n",
    "        assert (-1e-04 < self.gradient_F(a, b)).all() and (self.gradient_F(a, b) < 1e-04).all(), \"Недостаточно шагов градиентного спуска\"\n",
    "        \n",
    "    def fit(self, a, b):\n",
    "        w_start = np.zeros(a.shape[1]+1)\n",
    "        self.GD(a, b, w_start)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = Linear_Regression_GD(100)\n",
    "lr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.26257004e-16, 8.61866871e-16, 3.69462055e-16, 9.14049270e+01,\n",
       "       2.77050537e-01, 3.82522637e+01])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0QgIo9yp4r_y"
   },
   "source": [
    "### 8. Напечатайте уравнение гиперплоскости, полученной в результате применения модели линейной регрессии к данным X, y.\n",
    "Указание: Используйте print. Уравнение гиперплоскости должно иметь вид $y = w_0 + w_1 x_1+ w_2 x_2 + \\dots + w_m x_m$. Выводите коэффициенты гиперплоскости с точностью два знака после запятой. Учтите то, что эти коэффициенты могут быть и отрицательными. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'y = 0.00 + 0.00 * x1 + 0.00 * x2 + 91.40 * x3 + 0.28 * x4 + 38.25 * x5'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = f'y = {lr.w[0]:.2f}'\n",
    "\n",
    "for i in range(1, 6):\n",
    "    if lr.w[i] < 0:\n",
    "        s += f'{lr.w[i]:.2f} * x{i}'\n",
    "    else:\n",
    "        s += f' + {lr.w[i]:.2f} * x{i}'\n",
    "\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hfwuIMDG_0-H"
   },
   "source": [
    "### 9. Создайте новое наблюдение, например, взяв среднее значение по каждому столбцу X. Сделайте предсказание на нём.\n",
    "Указание: Обртите внимание, что метод predict принимает только двумерные numpy-массивы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.76185354,  0.8715765 ,  1.09439478,  0.183368  ,  0.02913489],\n",
       "       [-0.4309962 , -1.25135618, -0.54719179, -1.10687029,  1.33450613],\n",
       "       [-0.4478858 ,  1.97822297, -1.3211183 ,  0.85332424, -1.47937352],\n",
       "       ...,\n",
       "       [ 0.59134132,  0.83011766,  0.88931791,  0.34594367, -0.13007084],\n",
       "       [-0.45813699, -1.02662548, -0.53345245, -0.37753115,  1.25761311],\n",
       "       [-0.65422026, -1.17638185,  1.77584689,  1.29777381, -1.10805333]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.00192666e-03, -4.99308375e-03, -1.05279923e-02,\n",
       "         2.28467531e-06,  1.44162251e-02]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation = np.array([X.mean(axis=0)])\n",
    "observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.41085649])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_observation = lr.predict(observation)\n",
    "y_pred_observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uf7zZP4FcU1x"
   },
   "source": [
    "### 10. Создайте класс Linear_Regression_analytical, реализующий модель линейной регрессии, где оптимальное значение находится аналитически. Создайте экземпляр класса, обучите модель и выведите получившиеся коэффициенты гиперплоскости (смещение и веса). Сравните с результатами, полученными методом градиентного спуска.\n",
    "\n",
    "Указание: За основу возьмите класс Linear_Regression, только удалите в нём атрибут max_iter_ методы gradient_F и GD, а в методе fit возвращайте выражение: $(\\tilde{X}^T \\tilde{X})^{-1}\\tilde{X}\\vec y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear_Regression_Analitical():\n",
    "    def __init__(self):\n",
    "        self.w = None\n",
    "\n",
    "    def X_(self, X):\n",
    "        X_ones = np.ones((X.shape[0], 1))\n",
    "        return np.hstack([X_ones, X])\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.dot(X_(X), self.w)\n",
    "  \n",
    "    def fit(self, X, y):\n",
    "        return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QjU8kQMS4-mi"
   },
   "source": [
    "### 11. Создайте класс Linear_Regression_equation, реализующий модель линейной регрессии через решение нормального уравнения. Создайте экземпляр класса, обучите модель и выведите получившиеся коэффициенты гиперплоскости. Сравните с результатами, полученными аналитическим методом.\n",
    "\n",
    "Указание: За основу возьмите класс Linear_Regression_analitical, только в методе fit реализуйте решение матричного уравнения $\\tilde{X}^T\\tilde{X}\\vec w = \\tilde{X}^T\\vec y$. Это может быть сделано с помощью [numpy.linalg.solve](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.linalg.solve.html) решающего уравнение вида $А\\vec w = \\vec b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Замерьте время обучения моделей линейной регрессии, реализованных методом градиентного спуска, аналитическим методом и решением нормального уравнения на сгенерированных данных. Какая из них работает быстрее для данного набора данных?\n",
    "Указание: Для замера времени используйте %timeit.\n",
    "\n",
    "µs - это микросекунда (1 µs = 0,000001 sec), ms - это миллисекунда (1 ms = 0.001 sec)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n2yvqUwkGuno"
   },
   "source": [
    "### 13. Реализуйте в классе Linear_Regression_GD оптимизацию не методом градиентного спуска, а методом стохастического градиентного спуска. Назовите полученный класс Linear_Regression_SGD. Вычислите коэффициенты гиперплоскости w и убедитесь, что они получились примерно теми же.\n",
    "Указание: Изменения произведите в методе gradient_F таким образом, чтобы градиент вычислялся не на всех значениях X и y, а на случайно выбранных наблюдениях в количестве size=600. Перемешать индексы случайным образом и выбрать из них нужное количество можно при помощи [np.random.choice](https://numpy.org/doc/stable/reference/random/generated/numpy.random.choice.html). Не забудьте зафиксировать np.random.seed(42)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CxXDo2xxkYhn"
   },
   "source": [
    "# 14. Сравните время обучения моделей линейной регрессии, реализованных методом градиентного спуска и стохастического градиентного спуска с одинаковым количеством итераций градиентного спуска.\n",
    "Указание: Возьмите max_iter = 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rYi_Aoa-wAaX"
   },
   "source": [
    "### 15. Создайте класс модели линейной регрессии из библиотеки sklearn. Обучите модель на сгенерированных данных и убедитесь, что коэффициенты гиперплоскости и предсказанное значение будут примерно теми же, что и у модели градиентного спуска, написанной своими руками.\n",
    "\n",
    " Указание: Воспользуйтесь классом [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html). Оптимальное коэффициенты гиперплоскости выводятся так: смещение выводится при помощи атрибута intrecept_, а оптимальные веса при помощи атрибута coef_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Сделайте предсказание на новом наблюдении. Убедитесь, значение будет примерно теми же, что и у модели градиентного спуска, написанной своими руками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. Напечатайте название каждого признака, а рядом найденный вес, ему соответствующий. Сделайте вывод какой признак наиболее сильно влияет на целевую переменную? А какой наименее значим?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18. Визуализируйте значимость признаков на графике.\n",
    "Указание: Используйте для построения графика [bar](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.bar.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
