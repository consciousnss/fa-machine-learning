{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DY6KfR5twAZ2"
   },
   "source": [
    "## Семинар 4\n",
    "\n",
    "# Тема: Линейная регрессия с m признаками"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная регрессия – это модель линейной зависимости между признаками и целевой переменной.\n",
    "\n",
    "$X \\in{\\mathbb R}^{\\displaystyle n \\times m}$, $\\vec y \\in {\\mathbb R}^{1}$\n",
    "\n",
    "$X=\\begin{pmatrix}\n",
    "  x_{1 1} & x_{1 2}& \\dots & x_{1 m}\\\\\n",
    "   \\vdots &  \\vdots & \\dots &  \\vdots\\\\\n",
    "   x_{n 1} & x_{n 2}& \\dots & x_{n m}\n",
    "\\end{pmatrix}$ - матрица признаков, $\\quad \\vec{y}=\\begin{pmatrix}\n",
    "  y_1\\\\\n",
    "   \\vdots \\\\\n",
    "  y_n\n",
    "\\end{pmatrix}$ - вектор-столбец целевой переменной\n",
    "\n",
    "Модель: $\\hat{y} = w_0 + w_1 x_1+ w_2 x_2 + \\dots + w_m x_m$ - предсказанные значения (гиперплоскость)\n",
    "\n",
    "\n",
    "$\\left\\{\n",
    "\\begin{array}{ccc}\n",
    "\\hat{y}_1 = w_0 + w_1 x_{1 1}+ w_2 x_{1 2}+\\dots + w_m x_{1 m}\\\\\n",
    "\\hat{y}_2 = w_0 + w_1 x_{2 1}+ w_2 x_{2 2}+\\dots + w_m x_{2 m}\\\\\n",
    " \\ldots \\\\\n",
    "\\hat{y}_n = w_0 + w_1 x_{n 1}+ w_2 x_{n 2}+\\dots + w_m x_{n m}\\\\\n",
    "\\end{array}\n",
    "\\right.\n",
    "\\qquad \\Rightarrow \\qquad   \\hat{y}_i = w_0 + w_1 x_{i 1}+ w_2 x_{i 2}+\\dots + w_m x_{i m}, \\quad i= 1,\\dots , n $\n",
    "\n",
    "Ошибка MSE (mean squared error):\n",
    "$L =  \\frac{1}{n}\\sum_{i=1}^{n} (\\hat{y}_i - {y}_i)^2$\n",
    "\n",
    "Функция ошибки:\n",
    "$L(w_0, w_1, w_2,\\dots , w_m) =  \\frac{1}{n}\\sum_{i=1}^{n} ( w_0 + w_1 x_{i 1}+ w_2 x_{i 2}+\\dots + w_m x_{i m} - {y}_i)^2 \\quad \\longrightarrow_{w_0, w_1, w_2,\\dots , w_m} \\quad min$\n",
    "\n",
    "Найдём частные производные:\n",
    "\n",
    "$ \\frac{\\partial }{\\partial w_0}L(w_0,w_1, w_2,\\dots, w_m) =\\frac{2}{n}\\sum_{i=1}^{n} ( w_0 + w_1 x_{i 1}+ w_2 x_{i 2}+\\dots + w_m x_{i m} - {y}_i)$\n",
    "\n",
    "$\\frac{\\partial }{\\partial w_1}L(w_0,w_1, w_2,\\dots , w_m) =\\frac{2}{n}\\sum_{i=1}^{n} ( w_0 + w_1 x_{i 1}+ w_2 x_{i 2}+\\dots + w_m x_{i m} - {y}_i){x}_{i 1}$\n",
    "\n",
    "$\\frac{\\partial }{\\partial w_2}L(w_0,w_1, w_2,\\dots , w_m) =\\frac{2}{n}\\sum_{i=1}^{n} ( w_0 + w_1 x_{i 1}+ w_2 x_{i 2}+\\dots + w_m x_{i m} - {y}_i){x}_{i 2}$\n",
    "\n",
    "$\\dots$\n",
    "\n",
    "$\\frac{\\partial }{\\partial w_m}L(w_0,w_1, w_2,\\dots , w_m) =\\frac{2}{n}\\sum_{i=1}^{n} ( w_0 + w_1 x_{i 1}+ w_2 x_{i 2}+\\dots + w_m x_{i m} - {y}_i){x}_{i m}$\n",
    "\n",
    "**Метод градиентного спуска в случае линейной регрессии**\n",
    "\n",
    "$\\left\\{\n",
    "\\begin{array}{ccc}\n",
    "w_{0}^{j+1} = w_{0}^{j} - \\alpha \\frac{1}{n}\\sum_{i=1}^{n} (w_0^{j} + w_1^{j} {x}_{i 1} + w_2^{j} x_{i 2}+\\dots + w_m x_{i m} - {y}_i)\\\\\n",
    "w_{1}^{j+1} = w_{1}^{j} - \\alpha \\frac{1}{n}\\sum_{i=1}^{n} (w_0^{j} + w_1^{j} {x}_{i 1} + w_2^{j} x_{i 2}+\\dots + w_m x_{i m} - {y}_i){x}_{i 1}\\\\\n",
    "\\dots \\\\\n",
    "w_{m}^{j+1} = w_{m}^{j} - \\alpha \\frac{1}{n}\\sum_{i=1}^{n} (w_0^{j} + w_1^{j} {x}_{i 1} + w_2^{j} x_{i 2}+\\dots + w_m x_{i m} - {y}_i){x}_{i m}\\\n",
    "\\end{array}\n",
    "\\right.\n",
    ", \\quad j= 1,\\dots , k-1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JE3-i5DkwAZ9"
   },
   "source": [
    "### Матричный вид:\n",
    "\n",
    "Формулы очень громоздкие, запишем их в матричном виде:\n",
    "\n",
    "$\\tilde{X}=\\begin{pmatrix}\n",
    "1 &  x_{1 1} & x_{1 2}& \\dots & x_{1 m}\\\\\n",
    "   \\vdots &  \\vdots & \\dots &  \\vdots\\\\\n",
    "1 &  x_{n 1} & x_{n 2}& \\dots & x_{n m}\n",
    "\\end{pmatrix}$ - матрица признаков с добавленным столбцом из едениц,\n",
    "\n",
    "$\\quad \\vec{y}=\\begin{pmatrix}\n",
    "  y_1\\\\\n",
    "   \\vdots \\\\\n",
    "  y_n\n",
    "\\end{pmatrix}$ - вектор-столбец целевой переменной,\n",
    "\n",
    "$\\quad \\vec{w}=\\begin{pmatrix}\n",
    "w_0\\\\\n",
    "w_1\\\\\n",
    "\\vdots \\\\\n",
    "w_m\n",
    "\\end{pmatrix}$ - вектор-столбец параметров гиперплоскости,\n",
    "\n",
    "$\\vec{\\hat{y}} = \\tilde{X}\\vec{w}$ - вектор-столбец предсказанных значений\n",
    "\n",
    "Функция ошибки MSE: $L = \\frac{1}{n}(\\tilde{X}\\vec{w}- \\vec{y})^{T}(\\tilde{X}\\vec{w}- \\vec{y})$\n",
    "\n",
    "Найдём частные производные:\n",
    "\n",
    "$\\begin{pmatrix}\n",
    "  \\frac{\\partial L}{\\partial w_0}\\\\\n",
    "  \\frac{\\partial L}{\\partial w_1}\\\\\n",
    "   \\vdots \\\\\n",
    " \\frac{\\partial L}{\\partial w_m}\n",
    "\\end{pmatrix}=\\frac{2}{n}\\tilde{X}^T(\\tilde{X}\\vec{w}- \\vec{y})$\n",
    "\n",
    "**Метод градиентного спуска в случае линейной регрессии:**\n",
    "\n",
    "$\\vec{w}^{j+1} = \\vec{w}^{j} - \\alpha \\frac{1}{n}\\tilde{X}^T(\\tilde{X}\\vec{w}^{j+1}- \\vec{y}), \\quad j= 1,\\dots , k$\n",
    "\n",
    "Градиентный спуск может быть усовершенствован до стохастического градиентного спуска, при котором вычисления производятся не на всех данных, а на наборах объектов, выбранных случайным образом из всех данных, что уменьшает требования по памяти."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACeps3L6vUXM"
   },
   "source": [
    "## Аналитическое решение\n",
    "\n",
    "Найти вектор оптимальных весов $w$ можно аналитически.\n",
    "Нужно найти такой вектор весов $w$, чтобы  выполнялось матричное уравнение:\n",
    "\n",
    "$\\vec{{y}} = \\tilde{X}\\vec{w}$.\n",
    "\n",
    "Домножим слева обе части на $\\tilde{X}^T$:\n",
    "\n",
    "$\\tilde{X}^T\\vec{{y}} = \\tilde{X}^T\\tilde{X}\\vec{w}$.\n",
    "\n",
    "Матрица $\\tilde{X}^T\\tilde{X}$ - квадратная, тогда можно найти решение (вектор $\\vec{w}$) в виде:\n",
    "\n",
    "$\\vec{w} = {(\\tilde{X}^T\\tilde{X})}^{-1}\\tilde{X}^T\\vec{{y}}$.\n",
    "\n",
    "У этого метода есть недостаток.\n",
    "Нахождение матрицы ${(\\tilde{X}^T\\tilde{X})}^{-1}$ - операция вычислительно сложная в случае большого размера матрицы и нестабильная в случае малого определителя матрицы $\\tilde{X}^T\\tilde{X}$.\n",
    "\n",
    "На практике лучше находить вектор весов $\\vec w$ решением матричного уравнения\n",
    "$\\tilde{X}^T\\tilde{X}\\vec{w}= \\tilde{X}^T\\vec{{y}}$. Оно называется нормальным. Это может быть сделано с помощью функции [numpy.linalg.solve](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.linalg.solve.html).\n",
    "\n",
    "Для небольшого датасета быстрее будет получаться аналитическое решение, но для больших матриц $\\tilde{X}$ быстрее работает градиентный спуск, особенно его стохастическая версия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VtKkv70TwAZ_"
   },
   "source": [
    "Импортируем необходимые библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Yg-3Xb1uwAZ_",
    "ExecuteTime": {
     "end_time": "2024-10-09T12:49:35.112893Z",
     "start_time": "2024-10-09T12:49:32.207689Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "import time\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_diabetes"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели линейной регрессии на sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генерируем данные:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T12:49:35.150350Z",
     "start_time": "2024-10-09T12:49:35.128539Z"
    }
   },
   "source": [
    "X, y = make_regression(n_samples=1000, # число строк\n",
    "                          n_features=5,    # число признаков\n",
    "                          n_informative=5, # целевая переменная зависит от всех признаков\n",
    "                          noise = 5,\n",
    "                          bias = 2,\n",
    "                          random_state=42)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём модель (объект класса) линейной регрессии:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Y56H_RcgwAaX",
    "ExecuteTime": {
     "end_time": "2024-10-09T12:49:35.243064Z",
     "start_time": "2024-10-09T12:49:35.233934Z"
    }
   },
   "source": [
    "model = LinearRegression()"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем модель:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "iRMGN_qYwAaX",
    "outputId": "037e5c56-12d5-4456-d0cd-259c7645135b",
    "ExecuteTime": {
     "end_time": "2024-10-09T12:49:35.353811Z",
     "start_time": "2024-10-09T12:49:35.316948Z"
    }
   },
   "source": [
    "model.fit(X, y)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ],
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводим найденные коэффициенты линейной регрессии.\n",
    "\n",
    "Свободный коэффициент:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MIkqUYtPwAaY",
    "outputId": "f15d9117-4885-4df1-a981-f170ddc1194b",
    "ExecuteTime": {
     "end_time": "2024-10-09T12:49:35.459020Z",
     "start_time": "2024-10-09T12:49:35.441578Z"
    }
   },
   "source": [
    "model.intercept_"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.691426699296051)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Веса:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f_lOeOwrwAaY",
    "outputId": "c823742a-4203-4444-b48e-911aa4d3d073",
    "ExecuteTime": {
     "end_time": "2024-10-09T12:49:35.634979Z",
     "start_time": "2024-10-09T12:49:35.616431Z"
    }
   },
   "source": [
    "model.coef_"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28.34273825, 46.0063814 , 16.71776866, 24.63911531, 19.1812038 ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDblKsG4wAaA"
   },
   "source": [
    "### 1. Сгенерируйте данные и значения целевой переменной (метки) для задачи регрессии, имеющие 5 признаков и 10000 наблюдений. Причём целевая переменная должна зависеть только от 3 признаков. Запишите их в датафрейм, дав названия колонкам. Выведите первые 10 строк датафрейма, а также его описательную статистику.\n",
    "Указание: Для этого воспользуйтесь [make_regression](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html), задав параметры: число строк n_samples=10000, число признаков n_features=5, число признаков от которых зависит целевая переменная n_informative=3, фиксируем воспроизводимость случайных данных        random_state=0. Дайте названия колонкам датафрейма, например, признакам - x1, x2, ..., а целевой переменной - y. Описательная статистика выводится при помощи метода pandas [describe](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T12:49:35.894330Z",
     "start_time": "2024-10-09T12:49:35.869950Z"
    }
   },
   "source": [
    "X, y = make_regression(n_samples=10000, # число строк\n",
    "                          n_features=5,    # число признаков\n",
    "                          n_informative=3, # целевая переменная зависит от всех признаков\n",
    "                          random_state=42)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T12:49:36.055767Z",
     "start_time": "2024-10-09T12:49:36.042845Z"
    }
   },
   "source": [
    "X[:5]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.76185354,  0.8715765 ,  1.09439478,  0.183368  ,  0.02913489],\n",
       "       [-0.4309962 , -1.25135618, -0.54719179, -1.10687029,  1.33450613],\n",
       "       [-0.4478858 ,  1.97822297, -1.3211183 ,  0.85332424, -1.47937352],\n",
       "       [ 0.02050173,  0.75204638,  1.33321056,  0.65336838, -1.07119486],\n",
       "       [ 1.29914982,  0.33323053, -0.24733596,  0.33271933, -1.33314801]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T12:49:36.251057Z",
     "start_time": "2024-10-09T12:49:36.208139Z"
    }
   },
   "source": [
    "df = pd.DataFrame(X, columns=[f'x{i+1}' for i in range(X.shape[1])])\n",
    "df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            x1        x2        x3        x4        x5\n",
       "0    -0.761854  0.871577  1.094395  0.183368  0.029135\n",
       "1    -0.430996 -1.251356 -0.547192 -1.106870  1.334506\n",
       "2    -0.447886  1.978223 -1.321118  0.853324 -1.479374\n",
       "3     0.020502  0.752046  1.333211  0.653368 -1.071195\n",
       "4     1.299150  0.333231 -0.247336  0.332719 -1.333148\n",
       "...        ...       ...       ...       ...       ...\n",
       "9995 -0.108076  0.681314  0.390398  0.924574 -0.853174\n",
       "9996 -0.323143 -0.237544 -1.079891  0.334889 -0.378978\n",
       "9997  0.591341  0.830118  0.889318  0.345944 -0.130071\n",
       "9998 -0.458137 -1.026625 -0.533452 -0.377531  1.257613\n",
       "9999 -0.654220 -1.176382  1.775847  1.297774 -1.108053\n",
       "\n",
       "[10000 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.761854</td>\n",
       "      <td>0.871577</td>\n",
       "      <td>1.094395</td>\n",
       "      <td>0.183368</td>\n",
       "      <td>0.029135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.430996</td>\n",
       "      <td>-1.251356</td>\n",
       "      <td>-0.547192</td>\n",
       "      <td>-1.106870</td>\n",
       "      <td>1.334506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.447886</td>\n",
       "      <td>1.978223</td>\n",
       "      <td>-1.321118</td>\n",
       "      <td>0.853324</td>\n",
       "      <td>-1.479374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.020502</td>\n",
       "      <td>0.752046</td>\n",
       "      <td>1.333211</td>\n",
       "      <td>0.653368</td>\n",
       "      <td>-1.071195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.299150</td>\n",
       "      <td>0.333231</td>\n",
       "      <td>-0.247336</td>\n",
       "      <td>0.332719</td>\n",
       "      <td>-1.333148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>-0.108076</td>\n",
       "      <td>0.681314</td>\n",
       "      <td>0.390398</td>\n",
       "      <td>0.924574</td>\n",
       "      <td>-0.853174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>-0.323143</td>\n",
       "      <td>-0.237544</td>\n",
       "      <td>-1.079891</td>\n",
       "      <td>0.334889</td>\n",
       "      <td>-0.378978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.591341</td>\n",
       "      <td>0.830118</td>\n",
       "      <td>0.889318</td>\n",
       "      <td>0.345944</td>\n",
       "      <td>-0.130071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>-0.458137</td>\n",
       "      <td>-1.026625</td>\n",
       "      <td>-0.533452</td>\n",
       "      <td>-0.377531</td>\n",
       "      <td>1.257613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>-0.654220</td>\n",
       "      <td>-1.176382</td>\n",
       "      <td>1.775847</td>\n",
       "      <td>1.297774</td>\n",
       "      <td>-1.108053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T12:49:36.791250Z",
     "start_time": "2024-10-09T12:49:36.725740Z"
    }
   },
   "source": [
    "df.describe()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                 x1            x2            x3            x4            x5\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000\n",
       "mean      -0.001002     -0.004993     -0.010528      0.000002      0.014416\n",
       "std        0.989240      0.994265      1.005219      1.014868      0.997083\n",
       "min       -3.856375     -3.631539     -3.635200     -4.295391     -4.465604\n",
       "25%       -0.664076     -0.675572     -0.704792     -0.696539     -0.654058\n",
       "50%       -0.000210      0.006501     -0.019121      0.012872      0.006485\n",
       "75%        0.679485      0.662879      0.676844      0.683884      0.683468\n",
       "max        3.852731      4.479084      3.691625      3.926238      3.942331"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.001002</td>\n",
       "      <td>-0.004993</td>\n",
       "      <td>-0.010528</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.014416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.989240</td>\n",
       "      <td>0.994265</td>\n",
       "      <td>1.005219</td>\n",
       "      <td>1.014868</td>\n",
       "      <td>0.997083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.856375</td>\n",
       "      <td>-3.631539</td>\n",
       "      <td>-3.635200</td>\n",
       "      <td>-4.295391</td>\n",
       "      <td>-4.465604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.664076</td>\n",
       "      <td>-0.675572</td>\n",
       "      <td>-0.704792</td>\n",
       "      <td>-0.696539</td>\n",
       "      <td>-0.654058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.000210</td>\n",
       "      <td>0.006501</td>\n",
       "      <td>-0.019121</td>\n",
       "      <td>0.012872</td>\n",
       "      <td>0.006485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.679485</td>\n",
       "      <td>0.662879</td>\n",
       "      <td>0.676844</td>\n",
       "      <td>0.683884</td>\n",
       "      <td>0.683468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.852731</td>\n",
       "      <td>4.479084</td>\n",
       "      <td>3.691625</td>\n",
       "      <td>3.926238</td>\n",
       "      <td>3.942331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Убелитесь в том, что в сгенерированных данных целевая переменная действительно зависит от трёх переменных. \n",
    "Указание: Для этого вычислите матрицу корреляции, воспользовавшись методом [corr](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html) библиотеки pandas. Для наглядности изобразите её на тепловой карте [heatmap](https://seaborn.pydata.org/generated/seaborn.heatmap.html) библиотеки seaborn. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T12:49:37.533385Z",
     "start_time": "2024-10-09T12:49:37.488245Z"
    }
   },
   "source": [
    "df.corr()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          x1        x2        x3        x4        x5\n",
       "x1  1.000000 -0.002876  0.000074  0.000603  0.004908\n",
       "x2 -0.002876  1.000000  0.003873  0.012809 -0.002124\n",
       "x3  0.000074  0.003873  1.000000  0.007831 -0.011626\n",
       "x4  0.000603  0.012809  0.007831  1.000000  0.009227\n",
       "x5  0.004908 -0.002124 -0.011626  0.009227  1.000000"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.002876</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.004908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2</th>\n",
       "      <td>-0.002876</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003873</td>\n",
       "      <td>0.012809</td>\n",
       "      <td>-0.002124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x3</th>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.003873</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.007831</td>\n",
       "      <td>-0.011626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x4</th>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.012809</td>\n",
       "      <td>0.007831</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x5</th>\n",
       "      <td>0.004908</td>\n",
       "      <td>-0.002124</td>\n",
       "      <td>-0.011626</td>\n",
       "      <td>0.009227</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T12:49:38.599617Z",
     "start_time": "2024-10-09T12:49:37.978162Z"
    }
   },
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(df.corr(), annot=True, fmt='.2f')\n",
    "plt.title('Матрица корреляции')\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Напишите функцию X_, которая принимает матрицу X (двумерный numpy-массив) и присоединяет столбец единиц к X слева. Примените функцию к сгенерированным выше данным X.\n",
    "Указание: Можно воспользоваться методом concatenate, либо hstack."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T12:49:39.389660Z",
     "start_time": "2024-10-09T12:49:39.368887Z"
    }
   },
   "source": [
    "def X_(X):\n",
    "    X_ones = np.ones((X.shape[0], 1))\n",
    "    return np.hstack([X_ones, X])"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T12:49:39.554635Z",
     "start_time": "2024-10-09T12:49:39.538457Z"
    }
   },
   "source": [
    "X_(X)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.76185354,  0.8715765 ,  1.09439478,  0.183368  ,\n",
       "         0.02913489],\n",
       "       [ 1.        , -0.4309962 , -1.25135618, -0.54719179, -1.10687029,\n",
       "         1.33450613],\n",
       "       [ 1.        , -0.4478858 ,  1.97822297, -1.3211183 ,  0.85332424,\n",
       "        -1.47937352],\n",
       "       ...,\n",
       "       [ 1.        ,  0.59134132,  0.83011766,  0.88931791,  0.34594367,\n",
       "        -0.13007084],\n",
       "       [ 1.        , -0.45813699, -1.02662548, -0.53345245, -0.37753115,\n",
       "         1.25761311],\n",
       "       [ 1.        , -0.65422026, -1.17638185,  1.77584689,  1.29777381,\n",
       "        -1.10805333]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T12:49:40.057857Z",
     "start_time": "2024-10-09T12:49:40.029427Z"
    }
   },
   "source": [
    "pd.DataFrame(X_(X))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        0         1         2         3         4         5\n",
       "0     1.0 -0.761854  0.871577  1.094395  0.183368  0.029135\n",
       "1     1.0 -0.430996 -1.251356 -0.547192 -1.106870  1.334506\n",
       "2     1.0 -0.447886  1.978223 -1.321118  0.853324 -1.479374\n",
       "3     1.0  0.020502  0.752046  1.333211  0.653368 -1.071195\n",
       "4     1.0  1.299150  0.333231 -0.247336  0.332719 -1.333148\n",
       "...   ...       ...       ...       ...       ...       ...\n",
       "9995  1.0 -0.108076  0.681314  0.390398  0.924574 -0.853174\n",
       "9996  1.0 -0.323143 -0.237544 -1.079891  0.334889 -0.378978\n",
       "9997  1.0  0.591341  0.830118  0.889318  0.345944 -0.130071\n",
       "9998  1.0 -0.458137 -1.026625 -0.533452 -0.377531  1.257613\n",
       "9999  1.0 -0.654220 -1.176382  1.775847  1.297774 -1.108053\n",
       "\n",
       "[10000 rows x 6 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.761854</td>\n",
       "      <td>0.871577</td>\n",
       "      <td>1.094395</td>\n",
       "      <td>0.183368</td>\n",
       "      <td>0.029135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.430996</td>\n",
       "      <td>-1.251356</td>\n",
       "      <td>-0.547192</td>\n",
       "      <td>-1.106870</td>\n",
       "      <td>1.334506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.447886</td>\n",
       "      <td>1.978223</td>\n",
       "      <td>-1.321118</td>\n",
       "      <td>0.853324</td>\n",
       "      <td>-1.479374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020502</td>\n",
       "      <td>0.752046</td>\n",
       "      <td>1.333211</td>\n",
       "      <td>0.653368</td>\n",
       "      <td>-1.071195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.299150</td>\n",
       "      <td>0.333231</td>\n",
       "      <td>-0.247336</td>\n",
       "      <td>0.332719</td>\n",
       "      <td>-1.333148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.108076</td>\n",
       "      <td>0.681314</td>\n",
       "      <td>0.390398</td>\n",
       "      <td>0.924574</td>\n",
       "      <td>-0.853174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.323143</td>\n",
       "      <td>-0.237544</td>\n",
       "      <td>-1.079891</td>\n",
       "      <td>0.334889</td>\n",
       "      <td>-0.378978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.591341</td>\n",
       "      <td>0.830118</td>\n",
       "      <td>0.889318</td>\n",
       "      <td>0.345944</td>\n",
       "      <td>-0.130071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.458137</td>\n",
       "      <td>-1.026625</td>\n",
       "      <td>-0.533452</td>\n",
       "      <td>-0.377531</td>\n",
       "      <td>1.257613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.654220</td>\n",
       "      <td>-1.176382</td>\n",
       "      <td>1.775847</td>\n",
       "      <td>1.297774</td>\n",
       "      <td>-1.108053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 6 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Напишите функцию, вычисляющую предсказание значения целевой переменной, как линейную функцию признака $\\vec{\\hat{y}} =\\tilde{X}\\vec{w}$, где $\\tilde{X} $ - матрица признаков с присоединённым слева столбцом единиц. Назовите её predict. Вычислите её значения на сгенерированных данных X в случайной точке $w$."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T12:49:40.604150Z",
     "start_time": "2024-10-09T12:49:40.592220Z"
    }
   },
   "source": [
    "def predict(X, w):\n",
    "    return np.dot(X_(X), w)\n"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T12:49:41.070356Z",
     "start_time": "2024-10-09T12:49:41.053063Z"
    }
   },
   "source": [
    "predict(X, np.random.random(X.shape[1]+1))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.40212098, -0.31871408,  0.53748809, ...,  1.37512628,\n",
       "       -0.13684129,  0.06718536])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Напишите функцию ошибки (loss) линейной регрессии с множеством признаков в матричном виде. Примените функцию к сгенерированным выше данным X, y, а в качестве $w$ возьмите столбец случайных чисел.\n",
    "Указание: $L = \\frac{1}{n}(\\tilde{X}\\vec{w}- \\vec{y})^{T}(\\tilde{X}\\vec{w}- \\vec{y})$, здесь $\\tilde{X}$ - это матрица X c присоединённым к ней столбцом единиц слева, а n - число строк матрицы X. Число элементов в $w$ должно соответствовать количеству столбцов в $\\tilde{X}$."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T12:49:41.327867Z",
     "start_time": "2024-10-09T12:49:41.316950Z"
    }
   },
   "source": [
    "def loss(X, y, w):\n",
    "    return (1/X.shape[0]) * np.dot((predict(X, w) - y).T, predict(X, w) - y) "
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T12:49:41.803499Z",
     "start_time": "2024-10-09T12:49:41.781032Z"
    }
   },
   "source": [
    "loss(X, y, np.random.random(X.shape[1]+1))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(9678.516671255402)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dejU_eixwAaE"
   },
   "source": [
    "### 6. Напишите функцию, которая вычисляет градиент функции ошибки (loss) с множеством признаков в матричном виде. Примените функцию к сгенерированным выше данным X, y, а в качестве $w$ возьмите столбец случайных чисел.\n",
    "\n",
    "Указание: $\\overrightarrow{{grad} (L)}  = \\frac{2}{n}\\tilde{X}^T(\\tilde{X}\\vec w- \\vec y)$, здесь $\\tilde{X}$ - это матрица X c присоединённым к ней столбцом единиц слева, а n - число строк матрицы X. Назовите созданную функцию gradient_F. Примените функцию к сгенерированным выше данным X, y, а в качестве $w$ возьмите столбец случайных чисел."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T12:49:41.941470Z",
     "start_time": "2024-10-09T12:49:41.933959Z"
    }
   },
   "source": [
    "def gradient_f(X, y, w):\n",
    "    return (2/X.shape[0])*X_(X).transpose()@(predict(X, w) - y)"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T12:49:42.104566Z",
     "start_time": "2024-10-09T12:49:42.086134Z"
    }
   },
   "source": [
    "gradient_f(X, y, np.random.random(X.shape[1]+1))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1.68935061,    1.07576359,    0.73478498, -182.95379823,\n",
       "         -1.0514623 ,  -71.95918498])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cfvz4uwJwAaF"
   },
   "source": [
    "### 7. Создайте класс Linear_Regression_GD, реализующий модель линейной регрессии для данных имеющих произвольное количество признаков (столбцов). Создайте экземпляр класса, обучите модель и выведите получившиеся коэффициенты гиперплоскости (смещение и веса).\n",
    "Указание: Необходимо создать класс, реализующий метод градиентного спуска для функции ошибки L.\n",
    "Воспользуйтесь для этого классом GradientDiscent, написанный в предыдущих ноутбуках, подставив туда методы X_ и gradient_L. В методе fit задайте стартовое значение массивом нулей нужной длины. В функции GD параметры a и b можно заменить на X, y для наглядности."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class GradientDiscent():\n",
    "    def __init__(self, max_iter):\n",
    "        self.w = None\n",
    "        self.max_iter_ = max_iter\n",
    "    \n",
    "    def gradient_F(self, X, y):\n",
    "        \n",
    "        return ........\n",
    "        \n",
    "    def GD(self, a, b, w_start, learning_rate=0.2):\n",
    "        self.w = w_start\n",
    "\n",
    "        for _ in range(self.max_iter_):\n",
    "            self.w = self.w - learning_rate *self.gradient_F(a, b)\n",
    "        assert (-1e+06 < self.w).all() and (self.w < 1e+06).all(), \"Расходимость: слишком большой learning_rate, либо неудачно выбрана начальная точка, либо минимум не достигается\"\n",
    "        assert (-1e-04 < self.gradient_F(a, b)).all() and (self.gradient_F(a, b) < 1e-04).all(), \"Недостаточно шагов градиентного спуска\"\n",
    "        \n",
    "    def fit(self, a, b):\n",
    "        w_start = np.zeros(2)\n",
    "        self.GD(a, b, w_start)    "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T12:49:42.235018Z",
     "start_time": "2024-10-09T12:49:42.214758Z"
    }
   },
   "source": [
    "class Linear_Regression_GD():\n",
    "    def __init__(self, max_iter):\n",
    "        self.w = None\n",
    "        self.max_iter_ = max_iter\n",
    "\n",
    "    def X_(self, X):\n",
    "        X_ones = np.ones((X.shape[0], 1))\n",
    "        return np.hstack([X_ones, X])\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.dot(X_(X), self.w)\n",
    "    \n",
    "    def gradient_F(self, X, y):\n",
    "        return (2/X.shape[0])*X_(X).transpose()@(self.predict(X) - y)\n",
    "        \n",
    "    def GD(self, a, b, w_start, learning_rate=0.2):\n",
    "        self.w = w_start\n",
    "\n",
    "        for _ in range(self.max_iter_):\n",
    "            self.w = self.w - learning_rate *self.gradient_F(a, b)\n",
    "        assert (-1e+06 < self.w).all() and (self.w < 1e+06).all(), \"Расходимость: слишком большой learning_rate, либо неудачно выбрана начальная точка, либо минимум не достигается\"\n",
    "        assert (-1e-04 < self.gradient_F(a, b)).all() and (self.gradient_F(a, b) < 1e-04).all(), \"Недостаточно шагов градиентного спуска\"\n",
    "        \n",
    "    def fit(self, a, b):\n",
    "        w_start = np.zeros(a.shape[1]+1)\n",
    "        self.GD(a, b, w_start)    "
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T12:49:42.549650Z",
     "start_time": "2024-10-09T12:49:42.455832Z"
    }
   },
   "source": [
    "lr = Linear_Regression_GD(100)\n",
    "lr.fit(X, y)"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T12:49:42.599112Z",
     "start_time": "2024-10-09T12:49:42.574672Z"
    }
   },
   "source": [
    "lr.w"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.26257004e-16, 8.61866871e-16, 3.69462055e-16, 9.14049270e+01,\n",
       "       2.77050537e-01, 3.82522637e+01])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0QgIo9yp4r_y"
   },
   "source": [
    "### 8. Напечатайте уравнение гиперплоскости, полученной в результате применения модели линейной регрессии к данным X, y.\n",
    "Указание: Используйте print. Уравнение гиперплоскости должно иметь вид $y = w_0 + w_1 x_1+ w_2 x_2 + \\dots + w_m x_m$. Выводите коэффициенты гиперплоскости с точностью два знака после запятой. Учтите то, что эти коэффициенты могут быть и отрицательными. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T12:49:42.696819Z",
     "start_time": "2024-10-09T12:49:42.684613Z"
    }
   },
   "source": [
    "s = f'y = {lr.w[0]:.2f}'\n",
    "\n",
    "for i in range(1, 6):\n",
    "    if lr.w[i] < 0:\n",
    "        s += f'{lr.w[i]:.2f} * x{i}'\n",
    "    else:\n",
    "        s += f' + {lr.w[i]:.2f} * x{i}'\n",
    "\n",
    "s"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'y = 0.00 + 0.00 * x1 + 0.00 * x2 + 91.40 * x3 + 0.28 * x4 + 38.25 * x5'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hfwuIMDG_0-H"
   },
   "source": [
    "### 9. Создайте новое наблюдение, например, взяв среднее значение по каждому столбцу X. Сделайте предсказание на нём.\n",
    "Указание: Обртите внимание, что метод predict принимает только двумерные numpy-массивы."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T12:49:42.886928Z",
     "start_time": "2024-10-09T12:49:42.869752Z"
    }
   },
   "source": [
    "X"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.76185354,  0.8715765 ,  1.09439478,  0.183368  ,  0.02913489],\n",
       "       [-0.4309962 , -1.25135618, -0.54719179, -1.10687029,  1.33450613],\n",
       "       [-0.4478858 ,  1.97822297, -1.3211183 ,  0.85332424, -1.47937352],\n",
       "       ...,\n",
       "       [ 0.59134132,  0.83011766,  0.88931791,  0.34594367, -0.13007084],\n",
       "       [-0.45813699, -1.02662548, -0.53345245, -0.37753115,  1.25761311],\n",
       "       [-0.65422026, -1.17638185,  1.77584689,  1.29777381, -1.10805333]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T12:49:43.079819Z",
     "start_time": "2024-10-09T12:49:43.063591Z"
    }
   },
   "source": [
    "observation = np.array([X.mean(axis=0)])\n",
    "observation"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.00192666e-03, -4.99308375e-03, -1.05279923e-02,\n",
       "         2.28467531e-06,  1.44162251e-02]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T12:49:43.319682Z",
     "start_time": "2024-10-09T12:49:43.305369Z"
    }
   },
   "source": [
    "y_pred_observation = lr.predict(observation)\n",
    "y_pred_observation"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.41085649])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uf7zZP4FcU1x"
   },
   "source": [
    "### 10. Создайте класс Linear_Regression_analytical, реализующий модель линейной регрессии, где оптимальное значение находится аналитически. Создайте экземпляр класса, обучите модель и выведите получившиеся коэффициенты гиперплоскости (смещение и веса). Сравните с результатами, полученными методом градиентного спуска.\n",
    "\n",
    "Указание: За основу возьмите класс Linear_Regression, только удалите в нём атрибут max_iter_ методы gradient_F и GD, а в методе fit возвращайте выражение: $(\\tilde{X}^T \\tilde{X})^{-1}\\tilde{X}\\vec y$"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T12:49:43.734120Z",
     "start_time": "2024-10-09T12:49:43.718956Z"
    }
   },
   "source": [
    "class Linear_Regression_Analitical():\n",
    "    def __init__(self):\n",
    "        self.w = None\n",
    "\n",
    "    def X_(self, X):\n",
    "        X_ones = np.ones((X.shape[0], 1))\n",
    "        return np.hstack([X_ones, X])\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.dot(X_(X), self.w)\n",
    "  \n",
    "    def fit(self, X, y):\n",
    "        self.w = np.linalg.inv(self.X_(X).T @ self.X_(X)) @ (self.X_(X).T @ y)\n"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T12:49:43.974582Z",
     "start_time": "2024-10-09T12:49:43.953277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lr_analitical = Linear_Regression_Analitical()\n",
    "lr_analitical.fit(X, y)\n",
    "lr_analitical.w"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.88657986e-15,  9.99200722e-16, -3.02535774e-15,  9.14049270e+01,\n",
       "        2.77050537e-01,  3.82522637e+01])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QjU8kQMS4-mi"
   },
   "source": [
    "### 11. Создайте класс Linear_Regression_equation, реализующий модель линейной регрессии через решение нормального уравнения. Создайте экземпляр класса, обучите модель и выведите получившиеся коэффициенты гиперплоскости. Сравните с результатами, полученными аналитическим методом.\n",
    "\n",
    "Указание: За основу возьмите класс Linear_Regression_analitical, только в методе fit реализуйте решение матричного уравнения $\\tilde{X}^T\\tilde{X}\\vec w = \\tilde{X}^T\\vec y$. Это может быть сделано с помощью [numpy.linalg.solve](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.linalg.solve.html) решающего уравнение вида $А\\vec w = \\vec b$."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T12:57:44.243345Z",
     "start_time": "2024-10-09T12:57:44.225947Z"
    }
   },
   "source": [
    "class Linear_Regression_equation:\n",
    "    def __init__(self):\n",
    "        self.w = None\n",
    "\n",
    "    def X_(self, X):\n",
    "        X_ones = np.ones((X.shape[0], 1))\n",
    "        return np.hstack([X_ones, X])\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X_tilde = self.X_(X)\n",
    "        \n",
    "        self.w = np.linalg.solve(X_tilde.T @ X_tilde,  X_tilde.T @ y)\n"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T12:57:45.195328Z",
     "start_time": "2024-10-09T12:57:45.172488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lr_e = Linear_Regression_equation()\n",
    "lr_e.fit(X, y)\n",
    "lr_e.w"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.89642828e-15,  9.74573822e-16, -2.99037959e-15,  9.14049270e+01,\n",
       "        2.77050537e-01,  3.82522637e+01])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Замерьте время обучения моделей линейной регрессии, реализованных методом градиентного спуска, аналитическим методом и решением нормального уравнения на сгенерированных данных. Какая из них работает быстрее для данного набора данных?\n",
    "Указание: Для замера времени используйте %timeit.\n",
    "\n",
    "µs - это микросекунда (1 µs = 0,000001 sec), ms - это миллисекунда (1 ms = 0.001 sec)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T12:49:44.593832Z",
     "start_time": "2024-10-09T12:49:44.587300Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n2yvqUwkGuno"
   },
   "source": [
    "### 13. Реализуйте в классе Linear_Regression_GD оптимизацию не методом градиентного спуска, а методом стохастического градиентного спуска. Назовите полученный класс Linear_Regression_SGD. Вычислите коэффициенты гиперплоскости w и убедитесь, что они получились примерно теми же.\n",
    "Указание: Изменения произведите в методе gradient_F таким образом, чтобы градиент вычислялся не на всех значениях X и y, а на случайно выбранных наблюдениях в количестве size=600. Перемешать индексы случайным образом и выбрать из них нужное количество можно при помощи [np.random.choice](https://numpy.org/doc/stable/reference/random/generated/numpy.random.choice.html). Не забудьте зафиксировать np.random.seed(42)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T12:49:44.859101Z",
     "start_time": "2024-10-09T12:49:44.851204Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CxXDo2xxkYhn"
   },
   "source": [
    "# 14. Сравните время обучения моделей линейной регрессии, реализованных методом градиентного спуска и стохастического градиентного спуска с одинаковым количеством итераций градиентного спуска.\n",
    "Указание: Возьмите max_iter = 1000."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T12:49:44.954849Z",
     "start_time": "2024-10-09T12:49:44.942453Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rYi_Aoa-wAaX"
   },
   "source": [
    "### 15. Создайте класс модели линейной регрессии из библиотеки sklearn. Обучите модель на сгенерированных данных и убедитесь, что коэффициенты гиперплоскости и предсказанное значение будут примерно теми же, что и у модели градиентного спуска, написанной своими руками.\n",
    "\n",
    " Указание: Воспользуйтесь классом [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html). Оптимальное коэффициенты гиперплоскости выводятся так: смещение выводится при помощи атрибута intrecept_, а оптимальные веса при помощи атрибута coef_. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T12:49:45.175415Z",
     "start_time": "2024-10-09T12:49:45.166931Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Сделайте предсказание на новом наблюдении. Убедитесь, значение будет примерно теми же, что и у модели градиентного спуска, написанной своими руками."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T12:49:45.389181Z",
     "start_time": "2024-10-09T12:49:45.379684Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. Напечатайте название каждого признака, а рядом найденный вес, ему соответствующий. Сделайте вывод какой признак наиболее сильно влияет на целевую переменную? А какой наименее значим?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T12:49:45.561852Z",
     "start_time": "2024-10-09T12:49:45.544780Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18. Визуализируйте значимость признаков на графике.\n",
    "Указание: Используйте для построения графика [bar](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.bar.html)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T12:49:45.674059Z",
     "start_time": "2024-10-09T12:49:45.668653Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
