{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Семинар 3\n",
    "\n",
    "# Тема: Линейная регрессия с одним и двумя признаками"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Парная линейная регрессия**\n",
    "\n",
    "Парная линейная регрессия – это модель линейной зависимости между одним признаком и целевой переменной.\n",
    "\n",
    "$\\vec{x}=\\begin{pmatrix}\n",
    "  x_1\\\\\n",
    "   \\vdots \\\\\n",
    "   x_n\n",
    "\\end{pmatrix}$ - признак, $\\quad \\vec{y}=\\begin{pmatrix}\n",
    "  y_1\\\\\n",
    "   \\vdots \\\\\n",
    "  y_n\n",
    "\\end{pmatrix}$ - целевая переменная\n",
    "\n",
    "\n",
    "**Модель:** $\\hat{y} = w_0 + w_1 x$ - предсказанные значения (прямая)\n",
    "\n",
    "\n",
    "$\\left\\{\n",
    "\\begin{array}{ccc}\n",
    "\\hat{y}_1 = w_0 + w_1 x_1\\\\\n",
    "\\hat{y}_2 = w_0 + w_1 x_2\\\\\n",
    " \\ldots \\\\\n",
    "\\hat{y}_n = w_0 + w_1 x_n\\\\\n",
    "\\end{array}\n",
    "\\right.\n",
    "\\qquad \\Rightarrow \\qquad   \\hat{y}_i = w_0 + w_1 x_i, \\quad i= 1,\\dots , n $\n",
    "\n",
    "Ошибка MSE (mean squared error):\n",
    "$MSE =  \\frac{1}{n}\\sum_{i=1}^{n} (\\hat{y}_i - {y}_i)^2$\n",
    "\n",
    "**Функция потерь $L(w_0, w_1)$:**\n",
    "    \n",
    "$L( w_0, w_1) =  \\frac{1}{n}\\sum_{i=1}^{n} (w_0 + w_1 {x}_i - {y}_i)^2 \\quad {\\longrightarrow}_{w_0, w_1} \\quad min$\n",
    "\n",
    "**Градиент функции потерь $L(w_0, w_1)$:**\n",
    "\n",
    "$ \\frac{\\partial }{\\partial w_0}L(w_{0},w_{1}) =\\frac{2}{n}\\sum_{i=1}^{n} (w_0 + w_1 {x}_i - {y}_i)$\n",
    "\n",
    "$\\frac{\\partial }{\\partial w_1}L(w_{0},w_{1}) =\\frac{2}{n}\\sum_{i=1}^{n} (w_0 + w_1 {x}_i - {y}_i){x}_i$\n",
    "\n",
    "**Метод градиентного спуска в случае парной линейной регрессии**\n",
    "\n",
    "Метод градиентного спуска для функции двух переменных $L(w_0, w_1)$:\n",
    "\n",
    "$\\left\\{\n",
    "\\begin{array}{ccc}\n",
    "w_{0}^{j+1} = w_{0}^{j} - \\alpha \\frac{\\partial }{\\partial w_0}L(w_{0}^{j},w_{1}^{j})\\\\\n",
    "w_{1}^{j+1} = w_{1}^{j} - \\alpha \\frac{\\partial }{\\partial w_1}L(w_{0}^{j},w_{1}^{j})\n",
    "\\end{array}\n",
    "\\right.\n",
    ", \\quad j= 0,\\dots , k-1$ \n",
    "\n",
    "$\\left\\{\n",
    "\\begin{array}{ccc}\n",
    "w_{0}^{j+1} = w_{0}^{j} - \\alpha \\frac{2}{n}\\sum_{i=1}^{n} (w_0^{j} + w_1^{j} {x}_i - {y}_i)\\\\\n",
    "w_{1}^{j+1} = w_{1}^{j} - \\alpha \\frac{2}{n}\\sum_{i=1}^{n} (w_0^{j} + w_1^{j} {x}_i - {y}_i){x}_i\n",
    "\\end{array}\n",
    "\\right.\n",
    ", \\quad j= 0,\\dots , k-1$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Линейная регрессия с двумя признаками**\n",
    "\n",
    "$X=\\begin{pmatrix}\n",
    "  x_{1 1} & x_{1 2}\\\\\n",
    "   \\vdots &  \\vdots \\\\\n",
    "   x_{n 1} & x_{n 2}\n",
    "\\end{pmatrix}$ - матрица признаков, $\\quad \\vec{y}=\\begin{pmatrix}\n",
    "  y_1\\\\\n",
    "   \\vdots \\\\\n",
    "  y_n\n",
    "\\end{pmatrix}$ - целевая переменная\n",
    "\n",
    "**Модель:** $\\hat{y} = w_0 + w_1 x_1 + w_2 x_2$ - предсказанные значения (плоскость)\n",
    "\n",
    "\n",
    "$\\left\\{\n",
    "\\begin{array}{ccc}\n",
    "\\hat{y}_1 = w_0 + w_1 x_{11} + w_2 x_{12}\\\\\n",
    "\\hat{y}_2 = w_0 + w_1 x_{21} + w_2 x_{22}\\\\\n",
    " \\ldots \\\\\n",
    "\\hat{y}_n = w_0 + w_1 x_{n1} + w_2 x_{n2}\\\\\n",
    "\\end{array}\n",
    "\\right.\n",
    "\\qquad \\Rightarrow \\qquad   \\hat{y}_i = w_0 + w_1 x_{i1} + w_2 x_{i2}, \\quad i= 1,\\dots , n $\n",
    "\n",
    "Ошибка MSE (mean squared error):\n",
    "$MSE =  \\frac{1}{n}\\sum_{i=1}^{n} (\\hat{y}_i - {y}_i)^2$\n",
    "\n",
    "**Функция потерь $L(w_0, w_1, w_3)$:**\n",
    "    \n",
    "$L( w_0, w_1, w_3) =  \\frac{1}{n}\\sum_{i=1}^{n} (w_0 + w_1 {x}_{i1}+ w_2 {x}_{i2} - {y}_i)^2 \\quad {\\longrightarrow}_{w_0, w_1, w_2} \\quad min$\n",
    "\n",
    "**Градиент функции потерь $L(w_0, w_1, w_2)$:**\n",
    "\n",
    "$ \\frac{\\partial }{\\partial w_0}L(w_{0},w_{1}, w_2) =\\frac{2}{n}\\sum_{i=1}^{n} (w_0 + w_1 {x}_{i1} + w_2 {x}_{i2} - {y}_i)$\n",
    "\n",
    "$\\frac{\\partial }{\\partial w_1}L(w_{0},w_{1}, w_2) =\\frac{2}{n}\\sum_{i=1}^{n} (w_0 + w_1 {x}_{i1} + w_2 {x}_{i2} - {y}_i){x}_{i1}$\n",
    "\n",
    "$\\frac{\\partial }{\\partial w_2}L(w_{0},w_{1}, w_2) =\\frac{2}{n}\\sum_{i=1}^{n} (w_0 + w_1 {x}_{i1} + w_2 {x}_{i2} - {y}_i){x}_{i2}$\n",
    "\n",
    "**Метод градиентного спуска в случае парной линейной регрессии**\n",
    "\n",
    "Метод градиентного спуска для функции двух переменных $L(w_0, w_1, w_2)$:\n",
    "\n",
    "$\\left\\{\n",
    "\\begin{array}{ccc}\n",
    "w_{0}^{j+1} = w_{0}^{j} - \\alpha \\frac{\\partial }{\\partial w_0}L(w_{0}^{j},w_{1}^{j},w_{2}^{j})\\\\\n",
    "w_{1}^{j+1} = w_{1}^{j} - \\alpha \\frac{\\partial }{\\partial w_1}L(w_{0}^{j},w_{1}^{j},w_{2}^{j})\\\\\n",
    "w_{2}^{j+1} = w_{2}^{j} - \\alpha \\frac{\\partial }{\\partial w_2}L(w_{0}^{j},w_{1}^{j},w_{2}^{j})\n",
    "\\end{array}\n",
    "\\right.\n",
    ", \\quad j= 0,\\dots , k-1$ \n",
    "\n",
    "$\\left\\{\n",
    "\\begin{array}{ccc}\n",
    "w_{0}^{j+1} = w_{0}^{j} - \\alpha \\frac{2}{n}\\sum_{i=1}^{n} (w_0^{j} + w_1^{j} {x}_{i1} + w_2^{j} {x}_{i2} - {y}_i)\\\\\n",
    "w_{1}^{j+1} = w_{1}^{j} - \\alpha \\frac{2}{n}\\sum_{i=1}^{n} (w_0^{j} + w_1^{j} {x}_{i1} + w_2^{j} {x}_{i2} - {y}_i){x}_{i1}\\\\\n",
    "w_{2}^{j+1} = w_{2}^{j} - \\alpha \\frac{2}{n}\\sum_{i=1}^{n} (w_0^{j} + w_1^{j} {x}_{i1} + w_2^{j} {x}_{i2} - {y}_i){x}_{i2}\n",
    "\\end{array}\n",
    "\\right.\n",
    ", \\quad j= 0,\\dots , k-1$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем необходимые библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T12:48:37.671191Z",
     "start_time": "2024-09-25T12:48:36.615874Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_regression"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T12:45:21.171429Z",
     "start_time": "2024-09-25T12:44:44.525598Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install -U scikit-learn",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.2-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\sergey\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (2.1.1)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.14.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.5.2-cp312-cp312-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/11.0 MB 4.8 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.8/11.0 MB 5.0 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.1/11.0 MB 5.8 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.0/11.0 MB 6.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.1/11.0 MB 7.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.7/11.0 MB 8.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 8.0 MB/s eta 0:00:00\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading scipy-1.14.1-cp312-cp312-win_amd64.whl (44.5 MB)\n",
      "   ---------------------------------------- 0.0/44.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.8/44.5 MB 9.1 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 3.9/44.5 MB 9.4 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 5.8/44.5 MB 9.5 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 8.1/44.5 MB 9.7 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 10.5/44.5 MB 10.1 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 12.6/44.5 MB 10.1 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 14.9/44.5 MB 10.3 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 17.3/44.5 MB 10.4 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 19.7/44.5 MB 10.5 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 22.0/44.5 MB 10.6 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 23.9/44.5 MB 10.7 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 26.2/44.5 MB 10.5 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 27.8/44.5 MB 10.4 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 29.6/44.5 MB 10.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 31.5/44.5 MB 10.1 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 33.0/44.5 MB 10.0 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 34.9/44.5 MB 9.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 37.0/44.5 MB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 38.8/44.5 MB 9.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 40.1/44.5 MB 9.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 41.7/44.5 MB 9.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 43.0/44.5 MB 9.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.3/44.5 MB 9.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.5/44.5 MB 9.0 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.2 scipy-1.14.1 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерация данных для задачи регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_regression(n_samples=100,\n",
    "                          n_features=3,\n",
    "                          n_informative=3,\n",
    "                          noise = 5,\n",
    "                          bias = 1,\n",
    "                          random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.09306151, -1.49125759,  0.39600671],\n",
       "       [-0.65240858, -0.39095338,  0.39009332],\n",
       "       [-0.87079715, -0.57884966, -0.68481009],\n",
       "       [ 1.13689136,  0.09772497, -0.1359497 ],\n",
       "       [-1.00021535, -1.5447711 ,  0.84436298]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первый признак:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.09306151, -0.65240858, -0.87079715,  1.13689136, -1.00021535,\n",
       "        0.61037938, -1.23482582,  0.37915174,  1.86755799,  0.68159452,\n",
       "       -1.45436567,  0.2799246 , -1.31590741, -0.54286148, -0.31932842,\n",
       "        1.33652795, -0.11610394,  0.1887786 ,  0.3563664 , -0.39944903,\n",
       "       -0.11054066, -0.15135721,  0.96939671,  1.84926373,  2.3039167 ,\n",
       "       -0.34791215, -2.77259276,  1.89588918,  0.57659082, -0.41361898,\n",
       "        0.61407937, -0.69456786,  1.07961859,  0.31721822, -0.09845252,\n",
       "        0.46566244,  0.85683061,  0.15650654,  1.0996596 ,  0.62523145,\n",
       "        0.12167502,  1.8831507 ,  1.9507754 ,  1.30184623,  0.31694261,\n",
       "        0.03183056,  1.71334272, -0.51080514,  0.7811981 , -0.35955316,\n",
       "        1.53277921, -0.59631404, -1.37495129,  0.08755124,  0.14404357,\n",
       "        0.48148147, -0.39727181,  0.72909056,  0.40015721, -0.94444626,\n",
       "       -0.21274028, -1.07993151,  0.8644362 ,  0.8024564 , -0.955945  ,\n",
       "        0.52106488, -1.61695604,  1.48051479, -0.30901297, -0.63432209,\n",
       "        0.46278226, -1.07075262, -1.1680935 ,  1.20237985,  0.37816252,\n",
       "       -1.04525337,  1.78587049, -0.4555325 , -0.86122569, -1.29285691,\n",
       "       -1.25279536,  1.49407907,  1.22244507,  0.05616534, -1.09940079,\n",
       "        0.94447949, -0.85409574, -0.72559738, -1.04855297, -0.31088617,\n",
       "        0.42833187,  0.17742614,  1.53637705,  0.1666735 , -0.23792173,\n",
       "        0.05216508,  0.42625873, -0.76991607,  0.77179055, -0.49803245])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Сгенерируйте данные и значения целевой переменной для задачи регрессии с 1 признаком и 50 наблюдениями. Запишите их в датафрейм, дав названия колонкам. Выведите первые 10 строк датафрейма, а также его описательную статистику.\n",
    "Указание: Для этого воспользуйтесь [make_regression](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html), задав параметры: число строк n_samples=50, число признаков n_features=1, число признаков от которых зависит целевая переменная n_informative=1, зашумлённость noise = 2 и смещение                  bias = 2, а также фиксируем воспроизводимость случайных данных random_state=42. Дайте названия колонкам датафрейма, например, признаку - x, а целевой переменной - y. Описательная статистика выводится при помощи метода pandas [describe](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Визуализируйте сгенерироавнные данные на диаграмме рассеивания.\n",
    "Указание: Воспользуйтесь для построения графика [scatter](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.scatter.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Напишите функцию, вычисляющую предсказание значения целевой переменной, как линейную функцию признака $\\hat{y} =w_0 + w_1 x$. Назовите её predict. Вычислите её значения на сгенерированных данных X в случайной точке $w$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Напишите и визуализируйте функцию ошибки (loss) линейной регрессии с одним признаком.\n",
    "Указание: $L(w_0, w_1) =  \\frac{1}{n}\\sum_{i=1}^{n} ( w_0 + w_1 x_{i} - {y}_i)^2$. Используйте функцию predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Реализуйте функцию, которая вычисляет градиент функции ошибки.\n",
    "Указание: $$ \\frac{\\partial }{\\partial w_0}L(w_{0},w_{1}) =\\frac{2}{n}\\sum_{i=1}^{n} (w_0 + w_1 {x}_i - {y}_i)$$,$$\\frac{\\partial }{\\partial w_1}L(w_{0},w_{1}) =\\frac{2}{n}\\sum_{i=1}^{n} (w_0 + w_1 {x}_i - {y}_i){x}_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Создайте класс, реализующий модель линейной регрессии Linear_Regression_dim1. Найдите оптимальные значения коэффициентов гиперплоскости.\n",
    "Указание: Необходимо создать класс, реализующий метод градиентного спуска для loss функции.\n",
    "Воспользуйтесь для этого классом GradientDiscent, написанный в предыдущих ноутбуках."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class GradientDiscent():\n",
    "    def __init__(self, max_iter):\n",
    "        self.w = None\n",
    "        self.max_iter_ = max_iter\n",
    "    \n",
    "    def gradient_F(self, X, y):\n",
    "        \n",
    "        return ........\n",
    "        \n",
    "    def GD(self, a, b, w_start, learning_rate=0.2):\n",
    "        self.w = w_start\n",
    "\n",
    "        for _ in range(self.max_iter_):\n",
    "            self.w = self.w - learning_rate *self.gradient_F(a, b)\n",
    "        assert (-1e+06 < self.w).all() and (self.w < 1e+06).all(), \"Расходимость: слишком большой learning_rate, либо неудачно выбрана начальная точка, либо минимум не достигается\"\n",
    "        assert (-1e-04 < self.gradient_F(a, b)).all() and (self.gradient_F(a, b) < 1e-04).all(), \"Недостаточно шагов градиентного спуска\"\n",
    "        \n",
    "    def fit(self, a, b):\n",
    "        w_start = np.zeros(2)\n",
    "        self.GD(a, b, w_start)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Напечатайте уравнение линии регрессии, полученной в результате применения модели линейной регрессии к данным X, y.\n",
    "Указание: Используйте print. Уравнение гиперплоскости должно иметь вид $y = w_0 + w_1 x$. Выводите коэффициенты линии регрессии с точностью два знака после запятой. Учтите то, что эти коэффициенты могут быть и отрицательными. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Создайте новое наблюдение, например, взяв среднее значение по столбцу X. Сделайте предсказание на нём.\n",
    "Указание: Обртите внимание, что метод predict принимает только двумерные numpy-массивы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Постройте найденную линию регрессии и диаграмму рассеивания данных на одном графике. Изобразите точкой на нём же предсказанное значение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Создайте класс Linear_Regression_dim1_plot, который реализует отрисовку всех промежуточных линий регрессии по шагам градиентного спуска на одном графике с диаграммой рассеивания данных.\n",
    "Указание: В классе Linear_Regression измените функцию GD, добавив построение линий регрессии на каждом шаге градиентного спуска, а в конце диаграмму рассеивания. Задайте с помощью style цвет начальной и оптимальной линий регрессии отличными от остальных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Напишите функцию MAE, вычисляющую среднюю абсолютную ошибку предсказания. Вычислите с помощью неё ошибку полученных предсказаний на данных X.\n",
    "Указание: $MAE = \\frac{1}{n}\\sum_{i=1}^n \\left|y_i - \\widehat{y}_i\\right|$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Создайте новые данные с бОльшим шумом (noise = 10), визуализируйте их. Найдите оптимальные значения параметров линии регрессии. Вычислите ошибку MAE и убедитесь, что в этом случае она увеличится."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Сгенерируйте данные и значения целевой переменной для задачи регрессии с 2 признаками и 50 наблюдениями. Запишите их в датафрейм, дав названия колонкам. Выведите первые 10 строк датафрейма, а также его описательную статистику.\n",
    "Указание: Для этого воспользуйтесь [make_regression](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html), задав параметры: число строк n_samples=50, число признаков n_features=2, число признаков от которых зависит целевая переменная n_informative=2, зашумлённость noise = 2 и смещение                  bias = 2, а также фиксируем воспроизводимость случайных данных random_state=42. Дайте названия колонкам датафрейма, например, признакам: x1, x2, а целевой переменной: y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Визуализируйте данные с двумя признаками на пространственной диаграмме рассеивания. Поверните пространственный график на нужный угол так, чтобы было видно, что почти все точки \"укладываются\" на плоскость."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Напишите функцию, вычисляющую предсказание значения целевой переменной, как линейную функцию двух признаков $\\hat{y} =w_0 + w_1 x_1+ w_2 x_2$. Назовите её predict. Вычислите её значения на сгенерированных данных X в случайной точке $w$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Напишите функцию gradient_F, которая вычисляет градиент функции ошибки линейной регрессии с двумя признаками. Вычислите её значения на сгенерированных данных X в случайной точке $w$.\n",
    "Указание: $L(w_0, w_1, w_2) =  \\frac{1}{n}\\sum_{i=1}^{n} ( w_0 + w_1 x_{i 1}+ w_2 x_{i 2} - {y}_i)^2 \\quad \\longrightarrow \\quad_{w_0, w_1, w_2} min$\n",
    "$$ \\frac{\\partial }{\\partial w_0}L =\\frac{2}{n}\\sum_{i=1}^{n} (w_0 + w_1 x_{i 1}+ w_2 x_{i 2} - {y}_i)$$,$$\\frac{\\partial }{\\partial w_1}L =\\frac{2}{n}\\sum_{i=1}^{n} (w_0 + w_1 x_{i 1}+ w_2 x_{i 2} - {y}_i){x}_{i 1}$$,$$\\frac{\\partial }{\\partial w_2}L =\\frac{2}{n}\\sum_{i=1}^{n} (x_0 + w_1 x_{i 1}+ w_2 x_{i 2} - {y}_i){x}_{i 2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. Постройте модель линейной регрессии с двумя признаками в виде класса Linear_Regression_dim2.  Обучите построенную модель и выведите оптимальные параметры плоскости регрессии.\n",
    "Указание: Преобразуйте класс Linear_Regression_dim1 так, чтобы он мог быть применим к данным с двумя признаками. Замените нужным образом методы gradient_F и predict, а в fit стартовую точку возьмите, состоящую из трёх нулей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18. Визуализируйте найденную гиперплоскость регрессии и пространственную диаграмму рассеивания данных на одном графике. Поверните пространственный график на нужный угол так, чтобы было видно, что почти все точки \"укладываются\" на плоскость."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
