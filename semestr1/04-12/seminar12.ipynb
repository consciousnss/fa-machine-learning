{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f9c65ea",
   "metadata": {},
   "source": [
    "## Семинар 12\n",
    "\n",
    "# Тема: Кросс-валидация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ac2260",
   "metadata": {},
   "source": [
    "**Разбиение выборки** - это разделение имеющихся данных на несколько частей для проведения процессов обучения и оценки качества алгоритма машинного обучения на полностью независимых наборах данных.\n",
    "\n",
    "### Способы разбиения выборки\n",
    "1. **hold-out** разбиение (отложенная выборка, т.е. на две части - обучающую и тестовую)\n",
    "2. **cross-validation** разбиение (на k наборов, имеющих обучающую и тестовую части)\n",
    "\n",
    "    #### Виды разбиений для перекрёстной прорверки:\n",
    "    1. **k-fold** (разбиение на k частей с примерно одинаковым количеством объектов в каждом, из которых получают k наборов обучающих и\n",
    "    тестовых выборок, в которых одна часть выступает в роли тестовой выборки, а объединение остальных — в роли обучающей)\n",
    "    2. **Stratified k-fold**(k-fold разбиение со стратификацией, т.е. все наборы содержат примерно такой же процент объектов каждого\n",
    "    класса, что и исходные данные)\n",
    "    2. **leave-one-out** (отложенный пример)\n",
    "    и др.\n",
    "\n",
    "**Кросс-валидация** (перекрёстная проверка) — это процедура для оценки обобщающей способности алгоритмов, состоящая из следующих этапов:\n",
    "\n",
    "1. Фиксируется число блоков k. \n",
    "\n",
    "2. Выборка разбивается на k блоков определённым образом и получается k наборов данных, в которых один блок выступает в роли тестовой выборки, а объединение остальных блоков — в роли тренировочной. \n",
    "\n",
    "3. Осуществляется k итераций обучения модели на тренировочной выборке и подсчёт метрик на тестовой.\n",
    "\n",
    "4. Итоговые метрики получаются усреднением k получившихся результатов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a38859d-f0c9-4fd1-a844-999df68cdf24",
   "metadata": {},
   "source": [
    "Импортируем необходимые библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "673c9240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, r2_score, root_mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.datasets import load_iris, load_wine, load_diabetes\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, LeaveOneOut, cross_val_score, cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5efe2aa-1475-46a2-bb48-441df851e5f0",
   "metadata": {},
   "source": [
    "Загрузим встроенные данные об ирисах и выведем их описание:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44d7f14f-a062-4dc4-bf3a-0cfcec436fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      ":Number of Instances: 150 (50 in each of three classes)\n",
      ":Number of Attributes: 4 numeric, predictive attributes and the class\n",
      ":Attribute Information:\n",
      "    - sepal length in cm\n",
      "    - sepal width in cm\n",
      "    - petal length in cm\n",
      "    - petal width in cm\n",
      "    - class:\n",
      "            - Iris-Setosa\n",
      "            - Iris-Versicolour\n",
      "            - Iris-Virginica\n",
      "\n",
      ":Summary Statistics:\n",
      "\n",
      "============== ==== ==== ======= ===== ====================\n",
      "                Min  Max   Mean    SD   Class Correlation\n",
      "============== ==== ==== ======= ===== ====================\n",
      "sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "============== ==== ==== ======= ===== ====================\n",
      "\n",
      ":Missing Attribute Values: None\n",
      ":Class Distribution: 33.3% for each of 3 classes.\n",
      ":Creator: R.A. Fisher\n",
      ":Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      ":Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. dropdown:: References\n",
      "\n",
      "  - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "    Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "    Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "  - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "    (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "  - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "    Structure and Classification Rule for Recognition in Partially Exposed\n",
      "    Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "    Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "  - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "    on Information Theory, May 1972, 431-433.\n",
      "  - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "    conceptual clustering system finds 3 classes in the data.\n",
      "  - Many, many more ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffe04b4-3841-4a8e-a68c-e53f85ccbace",
   "metadata": {},
   "source": [
    "Выделим признаки и целевую переменную:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63c8eb61-1982-4c3a-a6cc-eb7bb449d6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978b4922-200a-4454-81a7-941f60a8d0e1",
   "metadata": {},
   "source": [
    "Сделаем hold-out разбиение данных на обучающую и тестовую части:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3be68c07-0894-4d3b-af4e-29fed535d6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7201ed91-b0a1-4c48-9fc2-fc60f2707956",
   "metadata": {},
   "source": [
    "Обучим модель логистической регрессии на обучающих данных и найдём значение метрики accuracy на тестовых."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38cf5573-a3ee-46e7-931f-1d69c7541fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 1.0\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "print('accuracy =', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10407905-1515-4b0e-a60f-b4949cd70c86",
   "metadata": {},
   "source": [
    "Поскольку accuracy = 1, предполагаем, что модель всегда верно классифицирует данные. Проверим так ли это, проведя перекрёстную проверку."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d620732e-8aff-4401-aa72-0ab9a37bd932",
   "metadata": {},
   "source": [
    "Сделаем разбиение исходных данных на k-блоков с перемешиванием, где k = 3. Выведем индексы обучающих и тестовых частей каждого блока, а также их длины."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16580575-2dfe-44e0-84af-38bca09885e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0, Длинна train: 100, Длинна test: 50\n",
      "  Train: index=[  0   1   2   3   5   6   7   8  13  14  17  20  21  23  24  25  28  33\n",
      "  34  35  37  38  39  40  41  43  44  46  47  48  49  50  52  53  54  57\n",
      "  58  59  60  61  62  63  66  67  70  71  72  74  77  79  80  83  84  87\n",
      "  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 105 106\n",
      " 107 111 112 113 114 115 116 117 119 120 121 122 123 124 125 126 129 130\n",
      " 134 135 136 138 139 140 144 147 148 149]\n",
      "  Test:  index=[  4   9  10  11  12  15  16  18  19  22  26  27  29  30  31  32  36  42\n",
      "  45  51  55  56  64  65  68  69  73  75  76  78  81  82  85  86 104 108\n",
      " 109 110 118 127 128 131 132 133 137 141 142 143 145 146]\n",
      "Fold: 1, Длинна train: 100, Длинна test: 50\n",
      "  Train: index=[  1   2   3   4   6   9  10  11  12  14  15  16  17  18  19  20  21  22\n",
      "  26  27  29  30  31  32  36  37  38  41  42  45  46  48  50  51  52  54\n",
      "  55  56  57  58  59  61  63  64  65  68  69  71  72  73  74  75  76  78\n",
      "  79  81  82  85  86  87  88  90  91  92  99 100 102 103 104 106 107 108\n",
      " 109 110 112 115 116 118 121 124 126 127 128 129 130 131 132 133 136 137\n",
      " 139 140 141 142 143 144 145 146 147 149]\n",
      "  Test:  index=[  0   5   7   8  13  23  24  25  28  33  34  35  39  40  43  44  47  49\n",
      "  53  60  62  66  67  70  77  80  83  84  89  93  94  95  96  97  98 101\n",
      " 105 111 113 114 117 119 120 122 123 125 134 135 138 148]\n",
      "Fold: 2, Длинна train: 100, Длинна test: 50\n",
      "  Train: index=[  0   4   5   7   8   9  10  11  12  13  15  16  18  19  22  23  24  25\n",
      "  26  27  28  29  30  31  32  33  34  35  36  39  40  42  43  44  45  47\n",
      "  49  51  53  55  56  60  62  64  65  66  67  68  69  70  73  75  76  77\n",
      "  78  80  81  82  83  84  85  86  89  93  94  95  96  97  98 101 104 105\n",
      " 108 109 110 111 113 114 117 118 119 120 122 123 125 127 128 131 132 133\n",
      " 134 135 137 138 141 142 143 145 146 148]\n",
      "  Test:  index=[  1   2   3   6  14  17  20  21  37  38  41  46  48  50  52  54  57  58\n",
      "  59  61  63  71  72  74  79  87  88  90  91  92  99 100 102 103 106 107\n",
      " 112 115 116 121 124 126 129 130 136 139 140 144 147 149]\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 3,shuffle=True, random_state=42)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    print(\"Fold: {}, Длинна train: {}, Длинна test: {}\".format(i, len(train_index), len(test_index)))\n",
    "    print(f\"  Train: index={train_index}\")\n",
    "    print(f\"  Test:  index={test_index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9941e19-f4fe-434d-8fca-cd20baae66c1",
   "metadata": {},
   "source": [
    "Сделаем k-блочную перекрёстную проверку (k = 3) модели логистической регрессии для метрики accuracy, используя библиотечную функцию cross_val_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d277a8fa-102e-4163-af08-c995b6a29ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.  , 0.92, 0.98])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = cross_val_score(model,                  # модель\n",
    "                             X,                      # матрица признаков\n",
    "                             y,                      # вектор цели\n",
    "                             cv = kf,                # тип разбиения (можно указать просто число фолдов cv = 3)\n",
    "                             scoring = 'accuracy',   # метрика 'f1_macro','precision_macro', 'recall_macro'\n",
    "                                                             # 'f1_micro','precision_micro', 'recall_micro'\n",
    "                                                             # 'f1_weighted','precision_weighted', 'recall_weighted'\n",
    "                             n_jobs=-1)              # используются все ядра CPU\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339d0594-1393-46a7-b955-3ff5445be4fb",
   "metadata": {},
   "source": [
    "Найдём среднее по кросс-валидации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "430f0e0a-47c4-4484-b279-f1e06ec197e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f2eeb3-459b-4241-be34-ba2a18d95126",
   "metadata": {},
   "source": [
    "Делаем вывод, что модель классифицирует верно только 97% данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4dc90a-7cbb-4511-9c7f-13684ac5fec3",
   "metadata": {},
   "source": [
    "# Кросс-валидация в задаче классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93d0293",
   "metadata": {},
   "source": [
    "### 1. Загрузите встроенный датасет o классификации вина из библиотеки sklearn.datasets. Выведите его описание. Обозначьте за _X_ двумерный numpy-массив признаков, а за _X_frame_ датафрейм признаков с соответствующими названиями колонок. Выведите размеры и первые пять строк, полученного датафрейма. Обозначьте за _y_ одномерный numpy-массив, а за _y_series_  - серию со значениями целевой переменной. Определите количество классов и количество объектов в каждом классе для целевой переменной. Убедитесь в том, что в данных нет пропущенных значений и они все числовые.\n",
    "Указание: Для загрузки датасета [wine](https://scikit-learn.org/1.5/modules/generated/sklearn.datasets.load_wine.html) напишите wine = load_wine(). Для определения количества объектов в каждом классе используйте метод _.value_counts()_ библиотеки _pandas_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84134714-9301-4200-b1ab-4801120326de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c6d68e6-b7c0-468a-80d3-03ae8ef4ce78",
   "metadata": {},
   "source": [
    "### 2. Сделайте hold-out (на две части) разбиение данных на обучающую и тестовую части в соотношении 4:1 тремя способами: без перемешивания и с перемешиванием двумя разными способами. Выведите количество объектов, попавшых в обучающую и в тестовую части. Выведите на экран индексы объектов обучающей и тестовой частей для каждого разбиения.\n",
    "Указание: Используйте функцию train_test_split. Для разбиение без перемешивания, укажите параметр shuffle=False. Для разбиений с перемешиванием, зафиксируйте разные способы перемешивания, указав random_state=0 и  random_state=1. Для выведения индексов объектов, попавших в обучающую и тестовую выборки, передавайте в функцию датафрейм и серию (не numpy-массивы), а индексы выводите при помощи .index библиотеки pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f2cfcb-8513-415c-aa60-1b8ce084f1ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27f15dad",
   "metadata": {},
   "source": [
    "### 3.Обучите модель логистической регрессии LogisticRegression(max_iter=5000) на трёх наборах обучающих данных, полученных в предыдущем задании. Сделайте предсказания на соответствующих трёх наборах тестовых данных и вычислите значения метрики accuracy для каждого из наборов. Сделайте вывод о том, влияет ли способ разбиения на значение метрики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d9495c-8acc-4e60-b86a-6c251a3ea393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4561007",
   "metadata": {},
   "source": [
    "### 4. Сделайте разбиение исходных данных на k-блоков с перемешиванием, где k = 5. Выведите индексы обучающих и тестовых частей каждого блока.\n",
    "\n",
    "Указание: Используйте класс [KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) с параметрами n_splits = 5, shuffle=True, random_state=42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8379e62-d903-4a00-be50-403f6cb24508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e164e53b",
   "metadata": {},
   "source": [
    "### 5. Напишите свой код, осуществляющий k-блочную перекрёстную проверку (кросс-валидацию) с количеством блоков k = 5 модели логистической регрессии для метрики accuracy. Усредните полученный результат.\n",
    "\n",
    "Указание: Используйте индексы блоков, полученных в предыдущем задании."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c302f1-3cc7-4c99-80d6-57d5807a4c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10b95275",
   "metadata": {},
   "source": [
    "### 6. Сделайте k-блочную перекрёстную проверку с k = 5 модели логистической регрессии для метрики accuracy, используя библиотечную функцию cross_val_score. Убедитесь, что получится тот же результат, что и в предыдущем задании. Также выведите дисперсию по кросс-валидации.\n",
    "Указание: Функция [cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) позволяет осуществлять перекрёстную проверку для вычисления только одной метрики, которую нужно указать в параметре scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6d5e40-ddd4-4958-947c-552a6fda60bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "164e4b52-8652-4446-8cbc-8a1bb4f3835f",
   "metadata": {},
   "source": [
    "### 7. Сделайте k-блочную перекрёстную проверку с k = 5 модели логистической регрессии для двух метрик accuracy и F1-мера, используя библиотечную функцию cross_validate. Выведите полученные массивы со значениями метрик на обучающих и тестовых данных. Усредните их значения.\n",
    "Указание: Функция [cross_validate](https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.cross_validate.html) позволяет осуществлять перекрёстную проверку нескольких метрик, которые нужно указать списком в параметре scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901e826a-6785-42c0-8572-e9e7e55daeb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "947c0bae-f5d7-402e-b989-a0ecb12b058b",
   "metadata": {},
   "source": [
    "### 8. Сделайте разбиение исходных данных на k-блоков со стратификацией, число блоков возьмите равным 5. Выведите индексы обучающих и тестовых частей каждого блока. Выведите для полученных блоков обучающих данных количество объектов каждого класса, сравните результаты с количеством объектов каждого класса для целевой переменной в целом.\n",
    "\n",
    "Указание: Используйте класс [StratifiedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html) с параметрами n_splits = 5, shuffle=True, random_state=42. StratifiedKFold возвращает стратифицированные фолды, т.е. каждый блок содержит примерно такой же процент объектов каждого класса, что и полный набор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194b6489-e53b-43ad-8115-4d357065a17d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c5651db",
   "metadata": {},
   "source": [
    "### 9. Сделайте k-блочную перекрёстную проверку (k = 5) со стратификацией модели логистической регрессии для двух метрик accuracy и F1-мера, используя библиотечную функцию cross_validate. Выведите полученные массивы со значениями метрик на обучающих и тестовых данных. Усредните их значения.\n",
    "\n",
    "Указание: Для того, чтобы выводились массивы со значениями метрик на обучающих данных необходимо указать значения параметра return_train_score=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97061f1-1066-4455-ac47-705fa627404e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28ba67a-8599-49c8-89d0-c8691d36afbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a6495d4-0219-416c-89d3-ddd6d80e93ce",
   "metadata": {},
   "source": [
    "### 10. Сделайте leave-one-out разбиение данных. Выведите индексы обучающих и тестовых частей.\n",
    "\n",
    "Указание: Используйте  класс [LeaveOneOut](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneOut.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62de9e4f-3d63-4ebd-b81d-df3b59f7c1eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "420e451c",
   "metadata": {},
   "source": [
    "### 11. Сделайте перекрёстную проверку модели логистической регрессии для метрик accuracy и F1-мера, изпользуя leave-one-out разбиение. Выведите полученные массивы со значениями метрик на тестовых данных. Усредните их значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197e2743-38c5-493e-b701-3dba93622be1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9ea40d5",
   "metadata": {},
   "source": [
    "### 12. Напишите свой код, осуществляющий k-блочную перекрёстную проверку (k = 5) модели логистической регрессии для метрик accuracy и F1_мера с предварительным масштабированием данных методом стандартной нормализации. Усредните полученные результаты. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89d06d7-8bc0-4d25-98c4-e2c5d96ecdda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b783720-68f1-44b3-9ed9-4dc0e2942a7f",
   "metadata": {},
   "source": [
    "### 13. Сделайте k-блочную перекрёстную проверку (k = 5) модели логистической регрессии для двух метрик accuracy и F1-мера с предварительным масштабированием данных методом стандартной нормализации, используя библиотечную функцию cross_validate. Усредните значения метрик.\n",
    "\n",
    "Указание: Используйте конвейер, передайте его в функцию cross_validate в качестве параметра model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9d7765-ef22-4f32-a396-b69d7f975831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "533a318b-a4a3-4a78-a88a-8bad1ebcc28a",
   "metadata": {},
   "source": [
    "# Кросс-валидация в задаче регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292a8d96-950e-493e-876a-0e66d72e5c6f",
   "metadata": {},
   "source": [
    "### 1. Загрузите встроенный датасет o прогрессировании диабета из библиотеки sklearn.datasets. Выведите его описание. Обозначьте за _X_ двумерный numpy-массив признаков, а за _X_frame_ датафрейм признаков с соответствующими названиями колонок. Выведите размеры и первые пять строк, полученного датафрейма. Обозначьте за _y_ одномерный numpy-массив, а за _y_series_  - серию со значениями целевой переменной. Выведите количество уникальных значений целевой переменной. Убедитесь в том, что в данных нет пропущенных значений и они все числовые.\n",
    "Указание: Для загрузки датасета [diabetes](https://scikit-learn.org/1.5/modules/generated/sklearn.datasets.load_wine.html) напишите diabetes = load_diabetes(). Для определения количества объектов в каждом классе используйте метод _.value_counts()_ библиотеки _pandas_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42d43d4-98f2-467d-8dd9-81d854e59c8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ba4e600-0819-4bcc-b1c8-50e5301e08a6",
   "metadata": {},
   "source": [
    "### 2. Сделайте hold-out (на две части) разбиение данных на обучающую и тестовую части в соотношении 4:1, зафиксировав способ перемешивания данных, указав значение параметра random_state=5. Выведите количество объектов, попавших в обучающую и тестовую части. Обучите модель линейной регрессии на обучающих данных и сделайте предсказание на тестовых данных. Вычислите значения метрик коэффициент детерминации и RMSE. На основе полученных значений сделайте предположение о качестве модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece69de2-94de-45fe-b518-d08cd0f62d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50f5717e-34b9-4d60-a6c1-7e9a483eee20",
   "metadata": {},
   "source": [
    "### 3. Напишите свой код, осуществляющий k-блочную перекрёстную проверку с количеством блоков k = 10 модели линейной регрессии для метрик коэффициент детерминации и RMSE. Усредните полученные результаты. Сделайте окончательный вывод о возможности пименения модели линейной регрессии к этим данным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412cc488-c0e5-4368-84ad-9b7c44f56965",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcd999f4-bdd4-4fa1-a121-c348c090ff2c",
   "metadata": {},
   "source": [
    "### 4. Сделайте k-блочную перекрёстную проверку (k = 10) модели линейной регрессии для двух метрик коэффициент детерминации и ошибка RMSE, используя библиотечную функцию cross_validate. Выведите полученные массивы со значениями метрик и усредните их. Сравните полученные результаты с предыдущим пунктом.\n",
    "\n",
    "Указание: Укажите параметр scoring = ['r2', 'neg_root_mean_squared_error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61422f88-c613-4f5c-8b99-e850de2d714a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd5309bc-e8c0-4b45-b9f7-1d7654f2d8be",
   "metadata": {},
   "source": [
    "### 5. Вместо модели линейной регрессии, примените полиномиальную модель второй степени. Сделайте k-блочную перекрёстную проверку (k = 10) этой модели для метрик коэффициент детерминации и ошибки RMSE с предварительным масштабированием данных min-max методом, используя библиотечную функцию cross_validate. Усредните полученное значения метрик. Используйте конвейер make_pipeline. Построенная полиномиальная модель описывает данные лучше линейной модели или нет?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c280a5e1-ea4d-4045-ac09-2525f6e225f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
