
## Линейные модели
Обучающую выборку можно представить как некое множество точек в многомерном пространстве
Причем в задачах регрессии целевая переменная воспринимается, как отдельное измерение

В задачах классификация целевая переменная не воспринимается как отдельное измерение

Линейные модели довольны просто -> быстро обучаются, но не способны учитывать сложные, нелинейные зависимости данных

## Полиномиальные модели


если в задаче классификации данные не могут быть разделены линией, можно выделить новый признак, увеличить количество измерений и, возможно, данные станут разделимы плоскостью (гиперплоскостью)

Атрибут - характеристика объекта реального мира, зафиксирован в наборе, каждый атрибут обладает определенным смыслом терминах предметной области
/
Признак - вектор, который подается на вход модели машинного обучения, мы можем создавать новые признаки на основе атрибутов

score - коэффициент детерминации 

https://youtu.be/xx-GCP9zAkc?si=PSMkVGnk0-w0ezyi&t=1536
построение полиномиальной модели 


с помощью пайплайнов (pipeline) можно автоматизировать трансформацию и обучение 

ну или использовать `.fit_transform`

```python
class_transform = PolynomialFeatures(degree=2)
X_2 = class_transform.fit_transform(X)
```


полиномиальные модели универсальны, при достаточно больших степенях предскажут все, что угодно

